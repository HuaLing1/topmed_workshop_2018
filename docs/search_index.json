[
["index.html", "TOPMed Analysis Workshop 1 Introduction", " TOPMed Analysis Workshop 2017-08-06 1 Introduction This site contains course materials for the TOPMed Analysis Workshop, August 7-9 2017. To work through the exercises, log into RStudio Server at http://52.25.72.68:8787 with your username and password. Slides for lectures will be posted here: https://www.nhlbiwgs.org/topmed-analysis-workshop-2017-materials Join the Slack channel here: https://join.slack.com/t/topmed-analysis-2017/signup If you are new to R, you might find the following material helpful: Introduction to R class from the Summer Institute in Statistical Genetics Graphics with ggplot2 tutorial Data manipulation with dplyr "],
["gds-format.html", "2 GDS format 2.1 Exploring a GDS file 2.2 Exercises", " 2 GDS format GDS is Genomic Data Structure, a storage format that can efficiently store genomic data and provide fast random access to subsets of the data. For more information on GDS for sequence data, read the SeqArray package vignette. 2.1 Exploring a GDS file To use the R packages developed at the DCC for sequence data, we first need to convert a VCF file to GDS. (If the file is BCF, use https://samtools.github.io/bcftools/bcftools.html to convert to VCF.) library(SeqArray) data.path &lt;- &quot;https://github.com/smgogarten/analysis_pipeline/raw/devel/testdata&quot; vcffile &lt;- &quot;1KG_phase3_subset_chr1.vcf.gz&quot; if (!file.exists(vcffile)) download.file(file.path(data.path, vcffile), vcffile) gdsfile &lt;- &quot;1KG_phase3_subset_chr1.gds&quot; seqVCF2GDS(vcffile, gdsfile, fmt.import=&quot;GT&quot;, storage.option=&quot;LZMA_RA&quot;, verbose=FALSE) We can interact with the GDS file using the SeqArray package. gds &lt;- seqOpen(gdsfile) gds ## Object of class &quot;SeqVarGDSClass&quot; ## File: /projects/users/stephanie/Code/TOPMed/topmed_workshop_2017/1KG_phase3_subset_chr1.gds (70.3K) ## + [ ] * ## |--+ description [ ] * ## |--+ sample.id { Str8 1126 LZMA_ra(9.66%), 877B } * ## |--+ variant.id { Int32 1120 LZMA_ra(17.5%), 793B } * ## |--+ position { Int32 1120 LZMA_ra(78.5%), 3.4K } * ## |--+ chromosome { Str8 1120 LZMA_ra(4.55%), 109B } * ## |--+ allele { Str8 1120 LZMA_ra(26.0%), 1.2K } * ## |--+ genotype [ ] * ## | |--+ data { Bit2 2x1126x1121 LZMA_ra(8.34%), 51.4K } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Int16 0 LZMA_ra, 18B } ## |--+ phase [ ] ## | |--+ data { Bit1 1126x1120 LZMA_ra(0.11%), 177B } * ## | |--+ extra.index { Int32 3x0 LZMA_ra, 18B } * ## | \\--+ extra { Bit1 0 LZMA_ra, 18B } ## |--+ annotation [ ] ## | |--+ id { Str8 1120 LZMA_ra(40.4%), 3.6K } * ## | |--+ qual { Float32 1120 LZMA_ra(2.46%), 117B } * ## | |--+ filter { Int32,factor 1120 LZMA_ra(2.46%), 117B } * ## | |--+ info [ ] ## | \\--+ format [ ] ## \\--+ sample.annotation [ ] # the unique sample identifier comes from the VCF header sample.id &lt;- seqGetData(gds, &quot;sample.id&quot;) length(sample.id) ## [1] 1126 head(sample.id) ## [1] &quot;HG00096&quot; &quot;HG00097&quot; &quot;HG00099&quot; &quot;HG00100&quot; &quot;HG00101&quot; &quot;HG00102&quot; # a unique integer ID is assigned to each variant variant.id &lt;- seqGetData(gds, &quot;variant.id&quot;) length(variant.id) ## [1] 1120 head(variant.id) ## [1] 1 2 3 4 5 6 # reference allele frequency of each variant afreq &lt;- seqAlleleFreq(gds) hist(afreq, breaks=50) We can define a filter on the gds object. After using the seqSetFilter command, all subsequent reads from the gds object are restricted to the selected subset of data, until a new filter is defined or seqResetFilter is called. seqSetFilter(gds, variant.id=1:10, sample.id=sample.id[1:5]) ## # of selected samples: 5 ## # of selected variants: 10 Genotype data is stored in a 3-dimensional array, where the first dimension is always 2 for diploid genotypes. The second and third dimensions are samples and variants, respectively. The values of the array denote alleles: 0 is the reference allele and 1 is the alternate allele. For multiallelic variants, other alternate alleles are represented as integers &gt; 1. geno &lt;- seqGetData(gds, &quot;genotype&quot;) dim(geno) ## [1] 2 5 10 geno[,,1:2] ## , , 1 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 ## ## , , 2 ## ## sample ## allele [,1] [,2] [,3] [,4] [,5] ## [1,] 0 0 0 0 0 ## [2,] 0 0 0 0 0 The SeqVarTools package has some additional functions for interacting with SeqArray-format GDS files. library(SeqVarTools) # return genotypes in matrix format getGenotype(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00097 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00099 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00100 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; ## HG00101 &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; &quot;0|0&quot; getGenotypeAlleles(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00097 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00099 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00100 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; ## HG00101 &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;C|C&quot; &quot;T|T&quot; &quot;G|G&quot; &quot;G|G&quot; &quot;A|A&quot; &quot;A|A&quot; &quot;C|C&quot; refDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 2 2 2 2 2 2 2 2 2 2 ## HG00097 2 2 2 2 2 2 2 2 2 2 ## HG00099 2 2 2 2 2 2 2 2 2 2 ## HG00100 2 2 2 2 2 2 2 2 2 2 ## HG00101 2 2 2 2 2 2 2 2 2 2 altDosage(gds) ## variant ## sample 1 2 3 4 5 6 7 8 9 10 ## HG00096 0 0 0 0 0 0 0 0 0 0 ## HG00097 0 0 0 0 0 0 0 0 0 0 ## HG00099 0 0 0 0 0 0 0 0 0 0 ## HG00100 0 0 0 0 0 0 0 0 0 0 ## HG00101 0 0 0 0 0 0 0 0 0 0 # look at reference and alternate alleles refChar(gds) ## [1] &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;T&quot; &quot;G&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;C&quot; altChar(gds) ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;A&quot; &quot;A&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; # reset the filter to all variants and samples seqResetFilter(gds) ## # of selected samples: 1,126 ## # of selected variants: 1,120 # how many alleles for each variant? n &lt;- seqNumAllele(gds) table(n) ## n ## 2 3 4 ## 1099 20 1 # some variants have more than one alternate allele multi.allelic &lt;- which(n &gt; 2) altChar(gds)[multi.allelic] ## [1] &quot;GT,G&quot; &quot;G,T&quot; &quot;A,T&quot; ## [4] &quot;A,T&quot; &quot;ATG,ATGTG&quot; &quot;C,G&quot; ## [7] &quot;A,T&quot; &quot;C,T&quot; &quot;A,C&quot; ## [10] &quot;TAA,T&quot; &quot;GTTA,GTTT&quot; &quot;GCC,GCCC,G&quot; ## [13] &quot;A,C&quot; &quot;A,C&quot; &quot;A,C&quot; ## [16] &quot;CAAGCAT,CGAGCAT&quot; &quot;CATTATT,C&quot; &quot;AT,C&quot; ## [19] &quot;TGTGA,C&quot; &quot;CCATT,CCATTCATT&quot; &quot;C,G&quot; # extract a particular alternate allele # first alternate altChar(gds, n=1)[multi.allelic] ## [1] &quot;GT&quot; &quot;G&quot; &quot;A&quot; &quot;A&quot; &quot;ATG&quot; &quot;C&quot; &quot;A&quot; ## [8] &quot;C&quot; &quot;A&quot; &quot;TAA&quot; &quot;GTTA&quot; &quot;GCC&quot; &quot;A&quot; &quot;A&quot; ## [15] &quot;A&quot; &quot;CAAGCAT&quot; &quot;CATTATT&quot; &quot;AT&quot; &quot;TGTGA&quot; &quot;CCATT&quot; &quot;C&quot; # second alternate altChar(gds, n=2)[multi.allelic] ## [1] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;T&quot; &quot;ATGTG&quot; ## [6] &quot;G&quot; &quot;T&quot; &quot;T&quot; &quot;C&quot; &quot;T&quot; ## [11] &quot;GTTT&quot; &quot;GCCC&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; ## [16] &quot;CGAGCAT&quot; &quot;C&quot; &quot;C&quot; &quot;C&quot; &quot;CCATTCATT&quot; ## [21] &quot;G&quot; # how many variants are SNVs vs INDELs? table(isSNV(gds, biallelic=TRUE)) ## ## FALSE TRUE ## 110 1010 table(isSNV(gds, biallelic=FALSE)) ## ## FALSE TRUE ## 99 1021 # 11 SNVs are multi-allelic seqClose(gds) 2.2 Exercises Set a filter selecting only multi-allelic variants. Inspect their genotypes using the different methods you learned above. Use the alleleDosage method to find dosage for the second (and third, etc.) alternate allele. Use the hwe function in SeqVarTools to run a Hardy-Weinberg Equilibrium test on each variant. Identify a variant with low p-value and inspect its genotypes. (Note that the HWE test is only valid for biallelic variants.) "],
["computing-a-grm.html", "3 Computing a GRM", " 3 Computing a GRM We can use the SNPRelate package to compute a Genetic Relationship matrix (GRM). library(SeqArray) data.path &lt;- &quot;https://github.com/smgogarten/analysis_pipeline/raw/devel/testdata&quot; gdsfile &lt;- &quot;1KG_phase3_subset_chr1.gds&quot; if (!file.exists(gdsfile)) download.file(file.path(data.path, gdsfile), gdsfile) gds &lt;- seqOpen(gdsfile) library(SNPRelate) grm &lt;- snpgdsGRM(gds, method=&quot;GCTA&quot;) ## Genetic Relationship Matrix (GRM, GCTA): ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed ## Excluding 13 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 1,126 samples, 1,107 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Sun Aug 6 21:54:33 2017 (internal increment: 680) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Sun Aug 6 21:54:33 2017 Done. names(grm) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;grm&quot; dim(grm$grm) ## [1] 1126 1126 seqClose(gds) "],
["pc-relate.html", "4 PC-Relate 4.1 KING 4.2 PC-AiR 4.3 PC-Relate 4.4 Comparison with pedigree 4.5 Exercise", " 4 PC-Relate To disentangle ancestry from recent familial relatedness, we use the PC-Relate method. 4.1 KING Step 1 is to get initial estimates of kinship using KING, which is robust to population structure but not admixture. The KING algorithm is available in SNPRelate. Typically we select a subset of variants for this calculation with LD pruning. # use a GDS file with all chromosomes library(SeqArray) data.path &lt;- &quot;https://github.com/smgogarten/analysis_pipeline/raw/devel/testdata&quot; gdsfile &lt;- &quot;1KG_phase3_subset.gds&quot; if (!file.exists(gdsfile)) download.file(file.path(data.path, gdsfile), gdsfile) gds &lt;- seqOpen(gdsfile) # use a subset of 100 samples to make things run faster workshop.path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2017/raw/master&quot; sampfile &lt;- &quot;samples_subset100.RData&quot; if (!file.exists(sampfile)) download.file(file.path(workshop.path, sampfile), sampfile) sample.id &lt;- TopmedPipeline::getobj(sampfile) # LD pruning to get variant set library(SNPRelate) snpset &lt;- snpgdsLDpruning(gds, sample.id=sample.id, method=&quot;corr&quot;, slide.max.bp=10e6, ld.threshold=sqrt(0.1)) ## SNV pruning based on LD: ## Excluding 1,120 SNVs on non-autosomes ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed ## Excluding 13,673 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 100 samples, 10,967 SNVs ## using 1 (CPU) core ## sliding window: 10,000,000 basepairs, Inf SNPs ## |LD| threshold: 0.316228 ## method: correlation ## Chromosome 1: 31.25%, 350/1,120 ## Chromosome 2: 31.61%, 354/1,120 ## Chromosome 3: 30.98%, 347/1,120 ## Chromosome 4: 30.98%, 347/1,120 ## Chromosome 5: 29.73%, 333/1,120 ## Chromosome 6: 31.16%, 349/1,120 ## Chromosome 7: 28.39%, 318/1,120 ## Chromosome 8: 26.07%, 292/1,120 ## Chromosome 9: 28.39%, 318/1,120 ## Chromosome 10: 28.30%, 317/1,120 ## Chromosome 11: 26.88%, 301/1,120 ## Chromosome 12: 28.39%, 318/1,120 ## Chromosome 13: 25.27%, 283/1,120 ## Chromosome 14: 24.29%, 272/1,120 ## Chromosome 15: 22.59%, 253/1,120 ## Chromosome 16: 22.41%, 251/1,120 ## Chromosome 17: 22.32%, 250/1,120 ## Chromosome 18: 23.66%, 265/1,120 ## Chromosome 19: 21.88%, 245/1,120 ## Chromosome 20: 20.80%, 233/1,120 ## Chromosome 21: 17.95%, 201/1,120 ## Chromosome 22: 17.32%, 194/1,120 ## 6,391 markers are selected in total. sapply(snpset, length) ## chr1 chr2 chr3 chr4 chr5 chr6 chr7 chr8 chr9 chr10 chr11 chr12 ## 350 354 347 347 333 349 318 292 318 317 301 318 ## chr13 chr14 chr15 chr16 chr17 chr18 chr19 chr20 chr21 chr22 ## 283 272 253 251 250 265 245 233 201 194 pruned &lt;- unlist(snpset, use.names=FALSE) # KING king &lt;- snpgdsIBDKING(gds, sample.id=sample.id, snp.id=pruned) ## IBD analysis (KING method of moment) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed ## Working space: 100 samples, 6,391 SNVs ## using 1 (CPU) core ## No family is specified, and all individuals are treated as singletons. ## Relationship inference in the presence of population stratification. ## CPU capabilities: Double-Precision SSE2 ## Sun Aug 6 21:54:36 2017 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Sun Aug 6 21:54:37 2017 Done. names(king) ## [1] &quot;sample.id&quot; &quot;snp.id&quot; &quot;afreq&quot; &quot;IBS0&quot; &quot;kinship&quot; dim(king$kinship) ## [1] 100 100 kingMat &lt;- king$kinship colnames(kingMat) &lt;- rownames(kingMat) &lt;- king$sample.id We extract pairwise kinship estimates and IBS0 to plot. kinship &lt;- snpgdsIBDSelection(king) head(kinship) ## ID1 ID2 IBS0 kinship ## 1 HG00110 HG00116 0.02534815 -0.01566265 ## 2 HG00110 HG00120 0.02722579 -0.02831325 ## 3 HG00110 HG00128 0.02472227 -0.01707317 ## 4 HG00110 HG00136 0.03004225 -0.04909639 ## 5 HG00110 HG00137 0.02675638 -0.03674699 ## 6 HG00110 HG00141 0.02925990 -0.04608434 library(ggplot2) ggplot(kinship, aes(IBS0, kinship)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() 4.2 PC-AiR The next step is PC-AiR, in which we select a set of unrelated samples that is maximally informative about all ancestries in the sample. We use this unrelated set for Principal Component Analysis (PCA), then project the relatives onto the PCs. First, we partition the samples into a related and unrelated set. We use a kinship threshold of degree 3 (unrelated is less than first cousins). We load the GENESIS package. In the first iteration, we use the KING estimates for both kinship (kinMat) and ancestry divergence (divMat). KING kinship estimates are negative for samples with different ancestry. library(GENESIS) sampset &lt;- pcairPartition(kinMat=kingMat, kin.thresh=2^(-9/2), divMat=kingMat, div.thresh=-2^(-9/2)) names(sampset) ## [1] &quot;rels&quot; &quot;unrels&quot; sapply(sampset, length) ## rels unrels ## 14 86 Typically we would repeat the LD pruning step on the set of unrelated samples we just identified, but for this example we will re-use the pruned set of variants from step 1. Using the SNPRelate package, we run PCA on the unrelated set and project values for the related set. # run PCA on unrelated set pca.unrel &lt;- snpgdsPCA(gds, sample.id=sampset$unrels, snp.id=pruned) ## Principal Component Analysis (PCA) on genotypes: ## Calculating allele counts/frequencies ... ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed ## Excluding 222 SNVs (monomorphic: TRUE, MAF: NaN, missing rate: NaN) ## Working space: 86 samples, 6,169 SNVs ## using 1 (CPU) core ## CPU capabilities: Double-Precision SSE2 ## Sun Aug 6 21:54:39 2017 (internal increment: 8952) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 1s ## Sun Aug 6 21:54:40 2017 Begin (eigenvalues and eigenvectors) ## Sun Aug 6 21:54:40 2017 Done. # project values for relatives snp.load &lt;- snpgdsPCASNPLoading(pca.unrel, gdsobj=gds) ## SNP loading: ## Working space: 86 samples, 6169 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Sun Aug 6 21:54:40 2017 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Sun Aug 6 21:54:40 2017 Done. samp.load &lt;- snpgdsPCASampLoading(snp.load, gdsobj=gds, sample.id=sampset$rels) ## Sample loading: ## Working space: 14 samples, 6169 SNPs ## using 1 (CPU) core ## using the top 32 eigenvectors ## Sun Aug 6 21:54:40 2017 (internal increment: 65536) ## [..................................................] 0%, ETC: --- [==================================================] 100%, completed in 0s ## Sun Aug 6 21:54:40 2017 Done. # combine unrelated and related PCs and order as in GDS file pcs &lt;- rbind(pca.unrel$eigenvect, samp.load$eigenvect) rownames(pcs) &lt;- c(pca.unrel$sample.id, samp.load$sample.id) samp.ord &lt;- match(sample.id, rownames(pcs)) pcs &lt;- pcs[samp.ord,] We need to determine which PCs are ancestry informative. To do this we need population information for the 1000 Genomes samples. This information is stored in an AnnotatedDataFrame, which is a data.frame with optional metadata describing the colunms. The class is defined in the Biobase package. We load the stored object using the getobj function from the TopmedPipeline package. library(Biobase) sampfile &lt;- &quot;sample_annotation.RData&quot; if (!file.exists(sampfile)) download.file(file.path(workshop.path, sampfile), sampfile) annot &lt;- TopmedPipeline::getobj(sampfile) annot ## An object of class &#39;AnnotatedDataFrame&#39; ## rowNames: 1 2 ... 2504 (1126 total) ## varLabels: sample.id subject.id ... status (6 total) ## varMetadata: labelDescription head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status ## 1 0 ## 2 1 ## 3 0 ## 4 1 ## 5 0 ## 6 0 varMetadata(annot) ## labelDescription ## sample.id sample identifier ## subject.id subject identifier ## Population population abbreviation ## Population.Description population description ## sex sex ## status simulated case/control status We make a parallel coordinates plot, color-coding by 1000 Genomes population. We load the dplyr package for data.frame manipulation. pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- 1:ncol(pcs) pc.df$sample.id &lt;- row.names(pcs) library(dplyr) annot &lt;- pData(annot) %&gt;% select(sample.id, Population) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) library(GGally) library(RColorBrewer) pop.cols &lt;- setNames(brewer.pal(12, &quot;Paired&quot;), c(&quot;ACB&quot;, &quot;ASW&quot;, &quot;CEU&quot;, &quot;GBR&quot;, &quot;CHB&quot;, &quot;JPT&quot;, &quot;CLM&quot;, &quot;MXL&quot;, &quot;LWK&quot;, &quot;YRI&quot;, &quot;GIH&quot;, &quot;PUR&quot;)) ggparcoord(pc.df, columns=1:12, groupColumn=&quot;Population&quot;, scale=&quot;uniminmax&quot;) + scale_color_manual(values=pop.cols) + xlab(&quot;PC&quot;) + ylab(&quot;&quot;) 4.3 PC-Relate The first 2 PCs separate populations, so we use them to compute kinship estimates adjusting for ancestry. The PC-Relate function expects a SeqVarData object, which allows linking sample and variant annotation with a GDS file in a single object. We will cover these in more detail later for association testing, but for now we create a bare object with no annotation. seqResetFilter(gds, verbose=FALSE) library(SeqVarTools) seqData &lt;- SeqVarData(gds) pcrel &lt;- pcrelate(seqData, pcMat=pcs[,1:2], training.set=sampset$unrels, scan.include=sample.id, snp.include=pruned) names(pcrel) ## [1] &quot;sample.id&quot; &quot;kinship&quot; &quot;ibd.probs&quot; &quot;nsnp&quot; &quot;kincorrect&quot; ## [6] &quot;k2correct&quot; &quot;call&quot; &quot;freq.type&quot; &quot;scale&quot; PC-Relate is an iterative method. Now that we have ancestry-adjusted kinship estimates, we can use them to better adjust for ancestry in the PCs. This time we use the pcair function, which combines partitioning the sample set and running PCA in one step. First we need to make a kinship matrix from the PC-Relate results. The KING matrix is still used for ancestry divergence. pcrelMat &lt;- pcrelateMakeGRM(pcrel, scaleKin=1) pca &lt;- pcair(seqData, v=32, kinMat=pcrelMat, kin.thresh=2^(-9/2), divMat=kingMat, div.thresh=-2^(-9/2), scan.include=sample.id, snp.include=pruned) names(pca) ## [1] &quot;vectors&quot; &quot;values&quot; &quot;sum.values&quot; &quot;rels&quot; &quot;unrels&quot; ## [6] &quot;kin.thresh&quot; &quot;div.thresh&quot; &quot;nsamp&quot; &quot;nsnps&quot; &quot;MAF&quot; ## [11] &quot;call&quot; &quot;method&quot; pcs &lt;- pca$vectors pc.df &lt;- as.data.frame(pcs) names(pc.df) &lt;- paste0(&quot;PC&quot;, 1:ncol(pcs)) pc.df$sample.id &lt;- row.names(pcs) pc.df &lt;- left_join(pc.df, annot, by=&quot;sample.id&quot;) ggplot(pc.df, aes(PC1, PC2, color=Population)) + geom_point() + scale_color_manual(values=pop.cols) Now we use the revised PCs to compute new kinship estimates. One can run the iteration multiple times and check for conversion, but usually two rounds are sufficient. pcrel &lt;- pcrelate(seqData, pcMat=pcs[,1:2], training.set=pca$unrels, scan.include=sample.id, snp.include=pruned) We plot the kinship estimates from PC-Relate, and notice that the values for less related pairs are much better behaved. kinship &lt;- pcrelateReadKinship(pcrel) ggplot(kinship, aes(k0, kin)) + geom_hline(yintercept=2^(-seq(3,9,2)/2), linetype=&quot;dashed&quot;, color=&quot;grey&quot;) + geom_point(alpha=0.5) + ylab(&quot;kinship estimate&quot;) + theme_bw() seqClose(gds) 4.4 Comparison with pedigree We can detect pedigree errors and sample identity problems by comparing the pedigree with empirical kinship estimates. We use a function from the GWASTools package, pedigreePairwiseRelatedness, to get expected pairwise relationships based on the pedigree. pedfile &lt;- &quot;sample_annotation.RData&quot; if (!file.exists(pedfile)) download.file(file.path(workshop.path, pedfile), pedfile) ped &lt;- TopmedPipeline::getobj(&quot;pedigree.RData&quot;) head(ped) ## family individ father mother sex ## 1 BB01 HG01879 0 0 M ## 2 BB01 HG01880 0 0 F ## 3 BB01 HG01881 HG01879 HG01880 F ## 4 BB02 HG01882 0 0 M ## 5 BB02 HG01883 0 0 F ## 6 BB02 HG01888 HG01882 HG01883 M pw &lt;- GWASTools::pedigreePairwiseRelatedness(ped) names(pw) ## [1] &quot;inbred.fam&quot; &quot;inbred.KC&quot; &quot;relativeprs&quot; rel &lt;- pw$relativeprs head(rel) ## Individ1 Individ2 relation kinship family ## 1 HG01879 HG01880 U 0.00 BB01 ## 2 HG01879 HG01881 PO 0.25 BB01 ## 3 HG01880 HG01881 PO 0.25 BB01 ## 4 HG01882 HG01883 U 0.00 BB02 ## 5 HG01882 HG01888 PO 0.25 BB02 ## 6 HG01883 HG01888 PO 0.25 BB02 table(rel$relation) ## ## Av FS GpGc HAv HS PO U ## 2 6 16 1 3 616 330 distinct(rel, relation, kinship) %&gt;% arrange(-kinship) ## relation kinship ## 1 PO 0.2500 ## 2 FS 0.2500 ## 3 HS 0.1250 ## 4 GpGc 0.1250 ## 5 Av 0.1250 ## 6 HAv 0.0625 ## 7 U 0.0000 ## assign degrees to expected relationship pairs rel &lt;- rel %&gt;% mutate(exp.rel=ifelse(kinship == 0.125, &quot;Deg2&quot;, ifelse(kinship == 0.0625, &quot;Deg3&quot;, relation)), pair=GWASTools::pasteSorted(Individ1, Individ2)) %&gt;% select(pair, family, relation, exp.rel) ## assign degrees to observed relationship pairs cut.dup &lt;- 1/(2^(3/2)) cut.deg1 &lt;- 1/(2^(5/2)) cut.deg2 &lt;- 1/(2^(7/2)) cut.deg3 &lt;- 1/(2^(9/2)) cut.k0 &lt;- 0.1 kinship &lt;- kinship %&gt;% mutate(obs.rel=ifelse(kin &gt; cut.dup, &quot;Dup&quot;, ifelse(kin &gt; cut.deg1 &amp; k0 &lt; cut.k0, &quot;PO&quot;, ifelse(kin &gt; cut.deg1, &quot;FS&quot;, ifelse(kin &gt; cut.deg2, &quot;Deg2&quot;, ifelse(kin &gt; cut.deg3, &quot;Deg3&quot;, &quot;U&quot;)))))) table(kinship$obs.rel) ## ## Deg2 Deg3 FS PO U ## 4 10 2 7 4927 # merge observed and expected relationships kin.obs &lt;- kinship %&gt;% select(ID1, ID2, kin, k0, obs.rel) %&gt;% mutate(pair=GWASTools::pasteSorted(ID1, ID2)) %&gt;% left_join(rel, by=&quot;pair&quot;) %&gt;% select(-pair) %&gt;% mutate(exp.rel=ifelse(is.na(exp.rel), &quot;U&quot;, exp.rel)) %&gt;% filter(!(exp.rel == &quot;U&quot; &amp; obs.rel == &quot;U&quot;)) table(kin.obs$exp.rel, kin.obs$obs.rel) ## ## Deg2 Deg3 FS PO ## U 4 10 2 7 ggplot(kin.obs, aes(k0, kin, color=obs.rel)) + geom_point() All the observed relationships were unexpected. These samples are from 1000 Genomes sequencing, and known relatives were excluded from the released data. Here we have detected some cryptic relatives that were not annotated in the pedigree. 4.5 Exercise Complete one round of iteration using all samples from the test dataset and plot the results. Be sure to examine the parallel coordinates plot to determine the appropriate number of PCs to give as an argument to pcrelate. "],
["phenotype-harmonization.html", "5 Phenotype Harmonization 5.1 Import phentoype files into R 5.2 Run some quick diagnostics on the files 5.3 Use using mixed models to compare studies 5.4 Final considerations", " 5 Phenotype Harmonization Because TOPMed comprises multiple, distinct studies, it is necessary to perform phenotype harmonization before running a cross-study analysis. Harmonization is generally performed by “harmonization unit”, which is defined as a group of subjects whose phenotypes can be similarly processed. In many cases, one study corresponds to one harmonization unit, but more complicated studies may require multiple harmonization units. For example, the Framingham Heart study has multiple subcohorts (Original, Offspring, etc.), with phenotypes measured differently for subjects in different cohorts. Since the phenotypes have been measured differently, the different subcohorts have to be harmonized separately. In this exercise, we assume that you have created a phenotype harmonization plan for height, sent it to members from three studies to perform the harmonization, and received a harmonized phenotype file from each study. We will generate some diagnostic information about the harmonized phenotype. The exercise uses 1000 Genomes data, with simulated phenotypes for study, age, and height. 5.1 Import phentoype files into R The first step is to read the files into R for processing. Before we begin, you need to download the data from github so you have access to it. repo_path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2017/raw/master&quot; pheno_files &lt;- c(&quot;pheno_data_study_1.txt&quot;, &quot;pheno_data_study_2.txt&quot;, &quot;pheno_data_study_3.txt&quot;) for (pheno_file in pheno_files) { if (!file.exists(pheno_file)) download.file(file.path(repo_path, pheno_file), pheno_file) } Next, read the study phenotype files into R. In this case, each file is tab-delimited and has the same phenotype variable names. study_1 &lt;- read.table(&quot;pheno_data_study_1.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_1) ## subject_id sex age height ## 1 HG00096 M 47 165.3 ## 2 HG00102 F 49 169.1 ## 3 HG00112 M 46 167.9 ## 4 HG00114 M 49 169.5 ## 5 HG00115 M 35 161.1 ## 6 HG00116 M 37 182.2 study_2 &lt;- read.table(&quot;pheno_data_study_2.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_2) ## subject_id sex age height ## 1 HG00099 F 40 185.5 ## 2 HG00103 M 50 190.8 ## 3 HG00106 F 51 165.5 ## 4 HG00107 M 39 195.8 ## 5 HG00109 M 48 181.5 ## 6 HG00111 F 42 194.9 study_3 &lt;- read.table(&quot;pheno_data_study_3.txt&quot;, header = TRUE, sep = &quot;\\t&quot;, as.is = TRUE) head(study_3) ## subject_id sex age height ## 1 HG00097 F 47 144.9 ## 2 HG00100 F 45 150.5 ## 3 HG00101 M 40 177.9 ## 4 HG00105 M 34 158.5 ## 5 HG00108 M 47 168.5 ## 6 HG00110 F 44 159.3 We will be looking at differences by harmonization unit (in this case, study), so add the study identifier to the data frame. study_1$study &lt;- &quot;study_1&quot; study_2$study &lt;- &quot;study_2&quot; study_3$study &lt;- &quot;study_3&quot; Combine the three different study data frames into one large data frame for joint analysis. Before doing this, we should check that the column headers are the same. all.equal(names(study_1), names(study_2)) ## [1] TRUE all.equal(names(study_1), names(study_3)) ## [1] TRUE library(dplyr) phen &lt;- dplyr::bind_rows(study_1, study_2, study_3) 5.2 Run some quick diagnostics on the files We can look at the distribution of phenotype data with text-based reports or with plots. First, inspect distributions with table for categorical traits and with summary for quantitative traits. The commads are shown here for study_1, but you should run them for study_2 and study_3 as well to see if you can see any differences. table(study_1$sex) ## ## F M ## 190 185 summary(study_1$age) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 32.00 41.00 45.00 45.17 49.00 62.00 summary(study_1$height) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 139.6 163.8 169.9 170.2 176.7 200.3 It is also helpful to use plots to inspect the distributions of phenotype data. Here, we will look at boxplots of height by study. library(ggplot2) ggplot(phen, aes(x = study, y = height)) + geom_boxplot() You may also want to see the difference in height when you include both study and sex: ggplot(phen, aes(x = study, fill = sex, y = height)) + geom_boxplot() These diagnostics are helpful to get a feel for the data. They can help you see if one study is vastly different from the others or detect outlier values. Some of the differences could be accounted for by covariates, so we will assess the statistical significance of study differences in the next section. 5.3 Use using mixed models to compare studies The quick diagnostics in the previous section let you see if the data from one study are completely different from the others, but such differences could be due to other factors that could be adjusted for in analysis. To account for these other factors, we need to fit a statistical model to the data. Because some of the studies in TOPMed have related individuals, we need to fit a mixed model to account for the correlation in the data. In this case, because the phenotype is quantitative, we will use a linear mixed model. More information about mixed models will be given during presentations tomorrow. We use the GENESIS R package for fitting the mixed model. This package can accept a correlation matrix as a random effect in the mixed model, instead of requiring a categorical or indicator variable. It therefore can account for the observed genetic relatedness between subjects. It is also the same package that we use for the association analyses, so this exercise provides a brief introduction to the package and some of the associated data structures. 5.3.1 Create an Annotated Data Frame The first step in fitting the mixed model is to create an Annotated Data Frame. This data structure is provided by the Bioconductor Biobase package, and it contains both the data and metadata. Next, create the Annotated Data Frame. You should include a description of each variable in the metadata. library(Biobase) metadata &lt;- data.frame(labelDescription = c( &quot;subject identifier&quot;, &quot;subject&#39;s sex&quot;, &quot;age at measurement of height&quot;, &quot;subject&#39;s height in cm&quot;, &quot;study identifier&quot; )) annot &lt;- AnnotatedDataFrame(phen, metadata) # access the data with the pData() function head(pData(annot)) ## subject_id sex age height study ## 1 HG00096 M 47 165.3 study_1 ## 2 HG00102 F 49 169.1 study_1 ## 3 HG00112 M 46 167.9 study_1 ## 4 HG00114 M 49 169.5 study_1 ## 5 HG00115 M 35 161.1 study_1 ## 6 HG00116 M 37 182.2 study_1 # access the metadata with the varMetadata() function varMetadata(annot) ## labelDescription ## subject_id subject identifier ## sex subject&#39;s sex ## age age at measurement of height ## height subject&#39;s height in cm ## study study identifier Save the AnnotatedDataFrame for future use. save(annot, file = &quot;phenotype_annotation.RData&quot;) 5.3.2 Obtain the genetic relatedness matrix Becase it is an input to the mixed model, we next need to download the genetic relatedness matrix calculated for these subjects. data_path &lt;- &quot;https://github.com/smgogarten/analysis_pipeline/raw/devel/testdata&quot; grmfile &lt;- &quot;grm.RData&quot; if (!file.exists(grmfile)) download.file(file.path(data_path, grmfile), grmfile) grm &lt;- TopmedPipeline::getobj(grmfile) rownames(grm$grm) &lt;- colnames(grm$grm) &lt;- grm$sample.id The GENESIS code to fit the mixed model also requires a sample.id column. Typically the sample.id column represents a sample identifier, not a subject id. In this case, we are only working with subject-level data, so we can use the subject identifier as the sample identifier for model-fitting purposes. annot$sample.id &lt;- annot$subject_id It also requires that the AnnotatedDataFrame sample.id is in the same order as the samples in the genetic relatedness matrix. # put the phenotype data in the same order as the GRM annot &lt;- annot[match(grm$sample.id, annot$sample.id), ] 5.3.3 Fit a mixed model without harmonization unit We will first fit a mixed model that allows us to see if the mean of the height phenotype is different by study after adjusting for other covariates. In this case, we will adjust for age and sex, but not for harmonization unit (study), because we are interested in seeing differences in mean height by harmonization unit. We will also include the genetic relatedness matrix as a random effect to account for relatedness between the participants. outcome &lt;- &quot;height&quot; covars &lt;- c(&quot;sex&quot;, &quot;age&quot;) covariance_matrices &lt;- grm$grm library(GENESIS) mod_1 &lt;- GENESIS::fitNullMM(annot, outcome = outcome, covars = covars, covMatList = covariance_matrices) ## [1] 107.6520433 107.6520433 -4584.2852579 0.9797695 ## [1] 104.9578627 108.1741689 -4584.0158948 0.9879743 ## [1] 54.201361 145.872003 -4580.515278 1.014609 ## [1] 59.006946 144.320038 -4580.480094 1.000327 ## [1] 59.10002 144.30106 -4580.48008 1.00000 ## [1] 59.09859 144.30237 -4580.48008 1.00000 ## [1] 59.09862 144.30235 -4580.48008 1.00000 The output of fitNullMM is a list with a number of named elements names(mod_1) ## [1] &quot;varComp&quot; &quot;varCompCov&quot; &quot;fixef&quot; ## [4] &quot;betaCov&quot; &quot;fitted.values&quot; &quot;resid.marginal&quot; ## [7] &quot;eta&quot; &quot;resid.conditional&quot; &quot;logLikR&quot; ## [10] &quot;logLik&quot; &quot;AIC&quot; &quot;RSS&quot; ## [13] &quot;workingY&quot; &quot;outcome&quot; &quot;model.matrix&quot; ## [16] &quot;cholSigmaInv&quot; &quot;scanID&quot; &quot;family&quot; ## [19] &quot;converged&quot; &quot;zeroFLAG&quot; &quot;hetResid&quot; ## [22] &quot;call&quot; The elements that we will work with in this exercise are: converged: an indicator of whether the model successfully converged model.matrix: The matrix of subject-covariate values used to fit the model fixef: The fitted fixed effects betaCov: The covariance of the fitted fixed effects resid.marginal: The (marginal) residuals from the model, which have been adjusted for the fixed effects but not for the covariance structure varComp: The fitted variance component for each input covariance matrix Make sure the model converged. mod_1$converged ## [1] TRUE Now, add the residuals to the phenotype data frame for plotting. We need to make sure that we are matching each residual value to the correct subject. In this case, we already ordered the AnnotatedDataFrame to match the genetic relatedness marix, but this may not always be the case (for example, if subjects are excluded due to missing phentoype data). To do match the same subject’s values together, we use the row names of the model.matrix element of the output, which are in the same order as the residual matrix, and the subject_id column of the annotated data frame. We then match the row names (and therefore the residuals) to the subject identifier in the phenotype file using the base R function match. j &lt;- match(annot$subject_id, rownames(mod_1$model.matrix)) annot$residuals &lt;- mod_1$resid.marginal[j] Next, we want to check if the different studies have the same mean height after adjustment for other covariates (here, age and sex). We will first do this qualitatively by making a boxplot of the residuals by study. ggplot(pData(annot), aes(x = study, y = residuals)) + geom_boxplot() From the boxplot, it is clear that the different studies have different mean heights. 5.3.4 Fit a model with harmonization unit Next, we can look at a model that adjusts for other covariates as well as harmonization unit. This model allows us to run a statistical test on the fitted study means and to qualitatively check if the variances are the same after adjusting for mean effects. The outcome is the same, but we now add the harmonization unit as a covariate. We also allow for group-specific residual variance by harmonization unit using the group.var argument to fitNullMM. # include the harmonization unit in the covariates covars &lt;- c(&quot;age&quot;, &quot;sex&quot;, &quot;study&quot;) mod_2 &lt;- GENESIS::fitNullMM(annot, outcome = outcome, covars = covars, group.var = &quot;study&quot;, covMatList = covariance_matrices) The fixef element now includes effects for study: mod_2$fixef ## Est SE Stat pval ## (Intercept) 164.27749628 3.04751310 2905.7951013 0.000000e+00 ## age 0.06043261 0.06642232 0.8277795 3.629154e-01 ## sexM 6.43122130 0.65686268 95.8600682 1.232974e-22 ## studystudy_2 10.59017952 0.78904317 180.1379060 4.521785e-41 ## studystudy_3 -8.94559707 0.82086206 118.7622189 1.180674e-27 First we’ll run a Wald test on the study effects to see how significant the mean difference is. The null hypothesis of this test is that all of the studies have the same mean height. First, identify the fixed effects and their covariance for the study indicator variables. There are only two studies in the fixed effects element because the other study is used as a reference group. # these rows are associated with the study effects idx &lt;- 4:5 # fixed effect estimates for the studies study_effect &lt;- mod_2$fixef[idx, ] study_effect ## Est SE Stat pval ## studystudy_2 10.590180 0.7890432 180.1379 4.521785e-41 ## studystudy_3 -8.945597 0.8208621 118.7622 1.180674e-27 # covariance of the study effects study_cov &lt;- mod_2$betaCov[idx, idx] study_cov ## studystudy_2 studystudy_3 ## studystudy_2 0.6225891 0.2308666 ## studystudy_3 0.2308666 0.6738145 Next, calculate the Wald test statistic and associated p-value. test_stat &lt;- t(study_effect$Est) %*% solve(study_cov) %*% study_effect$Est pval &lt;- pchisq(test_stat, df = length(study_effect), lower.tail = FALSE) pval ## [,1] ## [1,] 1.191252e-98 The small p-value indicates that the null hypothesis is rejected; the height measurements from the studies do not have the same mean height even after adjusting for the other covariates. Even if this test were not significant, though, the studies’ mean heights could still be different enough to indicate a problem with harmonization. Finally, we want to check if the height distributions from the different studies have the same variance. Start by looking at the variance components (varComp) element of the model. mod_2$varComp ## V_A V_study_1 V_study_3 V_study_2 ## 54.26533 42.80310 116.50950 98.08945 V_A represents the variance in height due to genetic relatedness. The other variance components (V_study_1, V_study_2, and V_study_3) represent the residual variance in each study. The fitted values of the variance components are different for the different studies, indicating that the distributions of height in the three studies have different variance even after accounting for the other covariates. We can also show the same information by plotting the residuals by study. We first have to add the residuals from this model to the AnnotatedDataFrame, again making sure to match them correctly by subject. j &lt;- match(annot$subject_id, rownames(mod_2$model.matrix)) annot$residuals &lt;- mod_2$resid.marginal[j] Next make a boxplot of the residuals by study. ggplot(pData(annot), aes(x = study, y = residuals)) + geom_boxplot() Both methods of looking at the variance components indicate that study 1 has a smaller residual variance than the others. It is more complicated to perform a test to see if the difference is statistically significant. The distribution of the null hypothesis is not a simple chi-squared distribution due to the fact that variance components cannot be negative. Therefore, we will only discuss the qualitative differences in variance between the studies at this point. 5.4 Final considerations We have determined that the different studies have both different mean and different variance by study for height. Before performing genotype-phenotype association tests with these data, you would need to think carefully about whether the phenotype is homogeneous enough to be analyzed together. In some cases, there may be a valid reason for different means or variances, for example: different heights in different study populations, such as a study composed primarily of Asian participants vs. a study with primarily European participants possible secular trends in height, such as comparing the Framingham Original cohort from ~1950 to a cohort from the present day In other cases, there may be good reasons to exclude one or more studies, for example: a systematic measurement error in one study miscalculation or misinterpretation of the harmonization algorithm study populations that are too different to be compared, such as trying to include a study composed primarily of children with one composed of adults in a height analysis It may be necessary to look at other variables that you had not previously considered. Studies may have used different measurement equipment or calibrated their data differently. There might also be other batch effects due to lab procedures or assays that could result in differences in the variance or mean by study. Unfortunately there is no single set of guidelines you can use to decide how to proceedw ith analysis of a phenotype. It is necessary to involve domain experts (e.g., the Working Group members) and study experts to determine whether the phenotype is homogeneous enough to analyze the studies together. "],
["finding-unharmonized-topmed-study-phenotypes-on-dbgap.html", "6 Finding unharmonized TOPMed study phenotypes on dbGaP 6.1 Ways to get TOPMed phenotype data 6.2 dbGaP accession lingo 6.3 dbGaP advanced search tools", " 6 Finding unharmonized TOPMed study phenotypes on dbGaP 6.1 Ways to get TOPMed phenotype data Get DCC harmonized phenotypes from the Exchange Area Get (harmonized or unharmonized) phenotypes directly from the studies (transfer via the Exchange Area) Get unharmonized phenotypes from dbGaP 6.2 dbGaP accession lingo study accession: A unique identifier, phs, that specifies a study on dbGaP parent accession: The phs that holds the subject, sample, and phenotype data for a study child accession: The phs that holds the genotype or other omics data for a project within a parent study TOPMed accession: The phs that will hold TOPMed sequence data Currently a separate parent phs Will eventually be made into a child phs connected to the original parent phs dataset accession: A unique identifier, pht, that specifies a dataset within a study variable accession: A unique identifier, phv, that specifies a variable 6.3 dbGaP advanced search tools 6.3.1 Entrez advanced search Search strings for Entrez # All variables within four studies (phs000007[Belongs To] OR phs000286[Belongs To] OR phs000284[Belongs To] OR phs000462[Belongs To]) # All variables with &quot;bmi&quot; in the variable name within four studies (phs000007[Belongs To] OR phs000286[Belongs To] OR phs000284[Belongs To] OR phs000462[Belongs To]) AND bmi[Variable Name] # All variables with &quot;bmi&quot; in the variable description within four studies (phs000007[Belongs To] OR phs000286[Belongs To] OR phs000284[Belongs To] OR phs000462[Belongs To]) AND bmi[Variable Description] # All variables with &quot;bmi&quot; in the variable name or description within four studies (phs000007[Belongs To] OR phs000286[Belongs To] OR phs000284[Belongs To] OR phs000462[Belongs To]) AND (bmi[Variable Description] OR bmi[Variable Name]) 6.3.2 Faceted advanced search Saved URLs for Faceted search examples ‘bmi’ in variable name or description within four studies ‘bmi’ and ‘weight’ in variable name or description within four studies ‘race’ or ‘ethnicity’ in variable name or description within four studies ‘race’ or ‘ethnicity’, and ‘self’ in variable name or description within four studies "],
["association-tests.html", "7 Association tests 7.1 Null model 7.2 Single-variant tests 7.3 Sliding window tests 7.4 Exercises 7.5 Annotation-based aggregate tests", " 7 Association tests Since TOPMed has many studies with related participants, we focus on linear mixed models. Logistic mixed models are also possible using GENESIS, see the GMMAT paper. 7.1 Null model The first step in an association test is to fit the null model. We will need an AnnotatedDataFrame with phenotypes, and a GRM. We have a sample annotation with a sample.id column matched to the GDS file, and a phenotype file with subject_id. (In this example, we use the 1000 Genomes IDs for both sample and subject ID.) For TOPMed data, it is also important to match by study, as subject IDs are not unique across studies. # sample annotation workshop.path &lt;- &quot;https://github.com/UW-GAC/topmed_workshop_2017/raw/master&quot; sampfile &lt;- &quot;sample_annotation.RData&quot; if (!file.exists(sampfile)) download.file(file.path(workshop.path, sampfile), sampfile) annot &lt;- TopmedPipeline::getobj(sampfile) library(Biobase) head(pData(annot)) ## sample.id subject.id Population Population.Description sex ## 1 HG00096 HG00096 GBR British in England and Scotland M ## 2 HG00097 HG00097 GBR British in England and Scotland F ## 3 HG00099 HG00099 GBR British in England and Scotland F ## 4 HG00100 HG00100 GBR British in England and Scotland F ## 5 HG00101 HG00101 GBR British in England and Scotland M ## 6 HG00102 HG00102 GBR British in England and Scotland F ## status ## 1 0 ## 2 1 ## 3 0 ## 4 1 ## 5 0 ## 6 0 # phenotypes by subject ID phenfile &lt;- &quot;phenotype_annotation.RData&quot; if (!file.exists(phenfile)) download.file(file.path(data.path, phenfile), phenfile) phen &lt;- TopmedPipeline::getobj(phenfile) head(pData(phen)) ## subject_id sex age height study ## 1 HG00096 M 47 165.3 study_1 ## 2 HG00102 F 49 169.1 study_1 ## 3 HG00112 M 46 167.9 study_1 ## 4 HG00114 M 49 169.5 study_1 ## 5 HG00115 M 35 161.1 study_1 ## 6 HG00116 M 37 182.2 study_1 varMetadata(phen) ## labelDescription ## subject_id subject identifier ## sex subject&#39;s sex ## age age at measurement of height ## height subject&#39;s height in cm ## study study identifier # merge sample annotation with phenotypes dat &lt;- pData(annot) %&gt;% left_join(pData(phen), by=c(&quot;subject.id&quot;=&quot;subject_id&quot;, &quot;sex&quot;=&quot;sex&quot;)) meta &lt;- bind_rows(varMetadata(annot), varMetadata(phen)[3:5,,drop=FALSE]) annot &lt;- AnnotatedDataFrame(dat, meta) # load the GRM data.path &lt;- &quot;https://github.com/smgogarten/analysis_pipeline/raw/devel/testdata&quot; grmfile &lt;- &quot;grm.RData&quot; if (!file.exists(grmfile)) download.file(file.path(data.path, grmfile), grmfile) grm &lt;- TopmedPipeline::getobj(grmfile) # the row and column names of the covariance matrix must be set to sample.id rownames(grm$grm) &lt;- colnames(grm$grm) &lt;- grm$sample.id We will test for an association between genotype and height, adjusting for sex, age, and study as covariates. If the sample set involves multiple distinct groups with different variances for the phenotype, we recommend allowing the model to use heterogeneous variance among groups with the parameter group.var. We saw in a previous exercise that the variance differs by study. library(GENESIS) nullmod &lt;- fitNullMM(annot, outcome=&quot;height&quot;, covars=c(&quot;sex&quot;, &quot;age&quot;, &quot;study&quot;), covMatList=grm$grm, group.var=&quot;study&quot;, verbose=FALSE) We also recommend taking an inverse normal transform of the residuals and refitting the model. This is done separately for each group, and the transformed residuals are rescaled. See the full procedure in the pipeline documenation. 7.2 Single-variant tests Single-variant tests are the same as in GWAS. We use the assocTestMM function in GENESIS. We have to create a SeqVarData object including both the GDS file and the sample annotation containing phenotypes. library(SeqVarTools) gdsfile &lt;- &quot;1KG_phase3_subset_chr1.gds&quot; if (!file.exists(gdsfile)) download.file(file.path(data.path, gdsfile), gdsfile) gds &lt;- seqOpen(gdsfile) seqData &lt;- SeqVarData(gds, sampleData=annot) assoc &lt;- assocTestMM(seqData, nullmod) head(assoc) ## snpID chr n MAF minor.allele Est SE Wald.Stat ## 1 1 1 1126 0.0039964476 alt -1.541280 3.733069 0.1704634 ## 2 2 1 1126 0.0492895204 alt -2.252667 1.347029 2.7966615 ## 3 3 1 1126 0.0004440497 alt -25.572126 11.039358 5.3659428 ## 4 4 1 1126 0.0008880995 alt -10.378157 10.233569 1.0284573 ## 5 5 1 1126 0.0071047957 alt 1.754369 2.635165 0.4432267 ## 6 6 1 1126 0.0022202487 alt -3.400914 5.669262 0.3598639 ## Wald.pval ## 1 0.67970027 ## 2 0.09446081 ## 3 0.02053369 ## 4 0.31052127 ## 5 0.50556915 ## 6 0.54858185 We make a QQ plot to examine the results. library(ggplot2) qqPlot &lt;- function(pval) { pval &lt;- pval[!is.na(pval)] n &lt;- length(pval) x &lt;- 1:n dat &lt;- data.frame(obs=sort(pval), exp=x/n, upper=qbeta(0.025, x, rev(x)), lower=qbeta(0.975, x, rev(x))) ggplot(dat, aes(-log10(exp), -log10(obs))) + geom_line(aes(-log10(exp), -log10(upper)), color=&quot;gray&quot;) + geom_line(aes(-log10(exp), -log10(lower)), color=&quot;gray&quot;) + geom_point() + geom_abline(intercept=0, slope=1, color=&quot;red&quot;) + xlab(expression(paste(-log[10], &quot;(expected P)&quot;))) + ylab(expression(paste(-log[10], &quot;(observed P)&quot;))) + theme_bw() } qqPlot(assoc$Wald.pval) 7.3 Sliding window tests For rare variants, we can do burden tests or SKAT on sliding windows using the GENESIS function assocTestSeqWindow. We restrict the test to variants with alternate allele frequency &lt; 0.1. (For real data, this threshold would be lower.) We use a flat weighting scheme. assoc &lt;- assocTestSeqWindow(seqData, nullmod, test=&quot;Burden&quot;, AF.range=c(0,0.1), weight.beta=c(1,1), window.size=5, window.shift=2) names(assoc) ## [1] &quot;param&quot; &quot;window&quot; &quot;nsample&quot; &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## chr window.start window.stop n.site dup burden.skew Score ## 1 1 966001 971000 1 0 11.036036 -0.1106805 ## 2 1 968001 973000 1 1 11.036036 -0.1106805 ## 3 1 970001 975000 1 1 11.036036 -0.1106805 ## 4 1 982001 987000 1 0 3.041979 -1.2395028 ## 5 1 984001 989000 1 1 3.041979 -1.2395028 ## 6 1 1022001 1027000 1 0 33.466573 -0.2090215 ## Var Score.stat Score.pval ## 1 0.071810741 0.1705897 0.67958828 ## 2 0.071810741 0.1705897 0.67958828 ## 3 0.071810741 0.1705897 0.67958828 ## 4 0.550238011 2.7921864 0.09472490 ## 5 0.550238011 2.7921864 0.09472490 ## 6 0.008173804 5.3451252 0.02078029 head(assoc$variantInfo) ## variantID allele chr pos n.obs freq weight ## 1 1 1 1 970546 1126 0.0039964476 1 ## 2 2 1 1 985900 1126 0.0492895204 1 ## 3 3 1 1 1025045 1126 0.0004440497 1 ## 4 4 1 1 1265550 1126 0.0008880995 1 ## 5 5 1 1 1472676 1126 0.0071047957 1 ## 6 6 1 1 1735725 1126 0.0022202487 1 qqPlot(assoc$results$Score.pval) For SKAT, we use the Wu weights. assoc &lt;- assocTestSeqWindow(seqData, nullmod, test=&quot;SKAT&quot;, AF.range=c(0,0.1), weight.beta=c(1,25), window.size=5, window.shift=2) head(assoc$results) ## chr window.start window.stop n.site dup Q_0 pval_0 err_0 ## 1 1 966001 971000 1 0 6.317493 0.67958828 0 ## 2 1 968001 973000 1 1 6.317493 0.67958828 0 ## 3 1 970001 975000 1 1 6.317493 0.67958828 0 ## 4 1 982001 987000 1 0 84.857944 0.09472490 0 ## 5 1 984001 989000 1 1 84.857944 0.09472490 0 ## 6 1 1022001 1027000 1 0 26.730269 0.02078029 0 head(assoc$variantInfo) ## variantID allele chr pos n.obs freq weight ## 1 1 1 1 970546 1126 0.0039964476 22.709172 ## 2 2 1 1 985900 1126 0.0492895204 7.431881 ## 3 3 1 1 1025045 1126 0.0004440497 24.734926 ## 4 4 1 1 1265550 1126 0.0008880995 24.472547 ## 5 5 1 1 1472676 1126 0.0071047957 21.067933 ## 6 6 1 1 1735725 1126 0.0022202487 23.701317 qqPlot(assoc$results$pval_0) 7.4 Exercises Logistic regression: fitNullMM can use a binary phenotype as the outcome variable by specifying the argument family=binomial. Use the status column in the sample annotation to fit a null model for simulated case/control status, with sex and Population as covariates. Refer to the documentation for fitNulMM to see what other parameters need to be changed for a binary outcome. Then run a single-variant test and a sliding window test using this model. Inverse normal transform: use the TopmedPipeline function addInvNorm to perform an inverse normal transform on the height variable. (You will need to load the TopmedPipeline library.) Inspect the code for this function by typing addInvNorm at the R prompt, so you understand what it is doing. Then for each study separately, compute a null model and do the inverse normal transform using just the values for that study. Compare these residuals with the initial residuals you obtained for that study by transforming all studies together. 7.5 Annotation-based aggregate tests Note: the code and libraries in this section are under active development, and are not production-level. It is provided to give workshop participants an example of some of the kinds of analysis tasks that might be performed with TOPMed annotation data. Use the code at your own risk, and be warned that it may break in unexpected ways. Github issues and contributions are welcome! Analysts generally aggregate rare variants for association testing to decrease multiple testing burden and increase statistical power. They can group variants that fall within arbitrary ranges (such as sliding-windows), or they can group variants with intent. For example, an analyst could aggregate variants that that fall between transcription start sites and stop sites, within coding regions, within regulatory regions, or other genomic features selected from sources like published gene models or position- or transcript-based variant annotation. An analyst could also choose to filter the variants prior or subsequent to aggregation using annotation-based criteria such as functional impact or quality scores. To demonstrate, we will aggregate a subset of TOPMed variants from chromosome 22. The subset is a portion of TOPMed SNP and indel variants that are also in the 1000 Genomes Project. We will parse an example variant annotation file to select fields of interest, parse a GENCODE .gtf file to define our genic units, and then aggregate the selected variants into the defined genic units. 7.5.1 Working with variant annotation Variants called from the TOPMed data set are annotated using the Whole Genome Sequence Annotator (WGSA). WGSA output files include 359 annotation fields, some of which are themselves lists of annotation values. Thus, individual variants may be annotated with more than 1000 individual fields. WGSA produces different output files for different featues. TOPMed variant annotation includes separate files for SNPs and for indels. The subsetted variant annotation files we will use for this example are available via github: ben.workshop.path &lt;- &quot;https://github.com/bheavner/topmed_workshop_2017_bh/raw/master&quot; snpfile &lt;- &quot;snp.tsv.gz&quot; if (!file.exists(snpfile)) download.file(file.path(ben.workshop.path, snpfile), snpfile) indelfile &lt;- &quot;indel.tsv.gz&quot; if (!file.exists(indelfile)) download.file(file.path(ben.workshop.path, indelfile), indelfile) The WGSA output files are tab-separated text files, with one line per annotated variant. Since there are many annotation fields, these files can be unwieldy to work with directly. As an example, the first two lines of the SNP variant annotation file can be previewed within R: readLines(&quot;snp.tsv.gz&quot;, n=2) ## [1] &quot;#chr\\tpos\\tref\\talt\\tANNOVAR_ensembl_Effect\\tANNOVAR_ensembl_Transcript_ID\\tANNOVAR_ensembl_Gene_ID\\tANNOVAR_ensembl_Closest_gene(intergenic_only)\\tANNOVAR_ensembl_HGVSc\\tANNOVAR_ensembl_HGVSp\\tANNOVAR_ensembl_Exon_Rank\\tANNOVAR_ensembl_summary\\tSnpEff_ensembl_Effect\\tSnpEff_ensembl_Effect_impact\\tSnpEff_ensembl_Sequence_feature\\tSnpEff_ensembl_Sequence_feature_impact\\tSnpEff_ensembl_Transcript_ID\\tSnpEff_ensembl_Transcript_biotype\\tSnpEff_ensembl_Gene_name\\tSnpEff_ensembl_Gene_ID\\tSnpEff_ensembl_HGVSc\\tSnpEff_ensembl_HGVSp\\tSnpEff_ensembl_Protein_position/Protein_len\\tSnpEff_ensembl_CDS_position/CDS_len\\tSnpEff_ensembl_cDNA_position/cDNA_len\\tSnpEff_ensembl_Exon_or_intron_rank/total\\tSnpEff_ensembl_Distance_to_feature\\tSnpEff_ensembl_Warnings\\tSnpEff_ensembl_LOF/NMD\\tSnpEff_ensembl_LOF/NMD_gene_name\\tSnpEff_ensembl_LOF/NMD_gene_ID\\tSnpEff_ensembl_LOF/NMD_num_transcripts_affected\\tSnpEff_ensembl_LOF/NMD_percent_transcripts_affected\\tSnpEff_ensembl_TF_binding_effect\\tSnpEff_ensembl_TF_name\\tSnpEff_ensembl_TF_ID\\tSnpEff_ensembl_summary\\tVEP_ensembl_Consequence\\tVEP_ensembl_Transcript_ID\\tVEP_ensembl_Gene_Name\\tVEP_ensembl_Gene_ID\\tVEP_ensembl_Protein_ID\\tVEP_ensembl_CCDS\\tVEP_ensembl_SWISSPROT\\tVEP_ensembl_Codon_Change_or_Distance\\tVEP_ensembl_Amino_Acid_Change\\tVEP_ensembl_HGVSc\\tVEP_ensembl_HGVSp\\tVEP_ensembl_cDNA_position\\tVEP_ensembl_CDS_position\\tVEP_ensembl_Protein_position\\tVEP_ensembl_Exon_or_Intron_Rank\\tVEP_ensembl_STRAND\\tVEP_ensembl_CANONICAL\\tVEP_ensembl_LoF\\tVEP_ensembl_LoF_filter\\tVEP_ensembl_LoF_flags\\tVEP_ensembl_LoF_info\\tVEP_ensembl_summary\\tANNOVAR_refseq_Effect\\tANNOVAR_refseq_Transcript_ID\\tANNOVAR_refseq_Gene_ID\\tANNOVAR_refseq_Closest_gene(intergenic_only)\\tANNOVAR_refseq_HGVSc\\tANNOVAR_refseq_HGVSp\\tANNOVAR_refseq_Exon_Rank\\tANNOVAR_refseq_summary\\tSnpEff_refseq_Effect\\tSnpEff_refseq_Effect_impact\\tSnpEff_refseq_Sequence_feature\\tSnpEff_refseq_Sequence_feature_impact\\tSnpEff_refseq_Transcript_ID\\tSnpEff_refseq_Transcript_biotype\\tSnpEff_refseq_Gene_name\\tSnpEff_refseq_Gene_ID\\tSnpEff_refseq_HGVSc\\tSnpEff_refseq_HGVSp\\tSnpEff_refseq_Protein_position/Protein_len\\tSnpEff_refseq_CDS_position/CDS_len\\tSnpEff_refseq_cDNA_position/cDNA_len\\tSnpEff_refseq_Exon_or_intron_rank/total\\tSnpEff_refseq_Distance_to_feature\\tSnpEff_refseq_Warnings\\tSnpEff_refseq_LOF/NMD\\tSnpEff_refseq_LOF/NMD_gene_name\\tSnpEff_refseq_LOF/NMD_gene_ID\\tSnpEff_refseq_LOF/NMD_num_transcripts_affected\\tSnpEff_refseq_LOF/NMD_percent_transcripts_affected\\tSnpEff_refseq_TF_binding_effect\\tSnpEff_refseq_TF_name\\tSnpEff_refseq_TF_ID\\tSnpEff_refseq_summary\\tVEP_refseq_Consequence\\tVEP_refseq_Transcript_ID\\tVEP_refseq_Gene_Name\\tVEP_refseq_Gene_ID\\tVEP_refseq_Protein_ID\\tVEP_refseq_Codon_Change_or_Distance\\tVEP_refseq_Amino_Acid_Change\\tVEP_refseq_HGVSc\\tVEP_refseq_HGVSp\\tVEP_refseq_cDNA_position\\tVEP_refseq_CDS_position\\tVEP_refseq_Protein_position\\tVEP_refseq_Exon_or_Intron_Rank\\tVEP_refseq_STRAND\\tVEP_refseq_CANONICAL\\tVEP_refseq_LoF\\tVEP_refseq_LoF_filter\\tVEP_refseq_LoF_flags\\tVEP_refseq_LoF_info\\tVEP_refseq_summary\\tANNOVAR_ucsc_Effect\\tANNOVAR_ucsc_Transcript_ID\\tANNOVAR_ucsc_Gene_ID\\tANNOVAR_ucsc_Closest_gene(intergenic_only)\\tANNOVAR_ucsc_HGVSc\\tANNOVAR_ucsc_HGVSp\\tANNOVAR_ucsc_Exon_Rank\\tANNOVAR_ucsc_summary\\trs_dbSNP147\\tsno_miRNA_name\\tsno_miRNA_type\\tUTR3_miRNA_target\\tTargetScan_context++_score_percentile\\tsplicing_consensus_ada_score\\tsplicing_consensus_rf_score\\tGWAS_catalog_rs\\tGWAS_catalog_trait\\tGWAS_catalog_pubmedid\\tGRASP_rs\\tGRASP_PMID\\tGRASP_p-value\\tGRASP_phenotype\\tGRASP_ancestry\\tGRASP_platform\\tclinvar_rs\\tclinvar_clnsig\\tclinvar_trait\\tclinvar_golden_stars\\tGTEx_V6_gene\\tGTEx_V6_tissue\\tMAP20\\tMAP35\\tMAP20(+-149bp)\\tMAP35(+-149bp)\\tGMS_single-end\\tGMS_paired-end\\t1000G_strict_masked\\tRepeatMasker_masked\\tAncestral_allele\\tAltaiNeandertal\\tDenisova\\tphyloP46way_primate\\tphyloP46way_primate_rankscore\\tphyloP46way_placental\\tphyloP46way_placental_rankscore\\tphyloP100way_vertebrate\\tphyloP100way_vertebrate_rankscore\\tphastCons46way_primate\\tphastCons46way_primate_rankscore\\tphastCons46way_placental\\tphastCons46way_placental_rankscore\\tphastCons100way_vertebrate\\tphastCons100way_vertebrate_rankscore\\tGERP_NR\\tGERP_RS\\tGERP_RS_rankscore\\tSiPhy_29way_logOdds\\tSiPhy_29way_logOdds_rankscore\\tintegrated_fitCons_score\\tintegrated_fitCons_rankscore\\tintegrated_confidence_value\\tGM12878_fitCons_score\\tGM12878_fitCons_rankscore\\tGM12878_confidence_value\\tH1-hESC_fitCons_score\\tH1-hESC_fitCons_rankscore\\tH1-hESC_confidence_value\\tHUVEC_fitCons_score\\tHUVEC_fitCons_rankscore\\tHUVEC_confidence_value\\tGenoCanyon_score\\tGenoCanyon_rankscore\\t1000Gp3_AC\\t1000Gp3_AF\\t1000Gp3_AFR_AC\\t1000Gp3_AFR_AF\\t1000Gp3_EUR_AC\\t1000Gp3_EUR_AF\\t1000Gp3_AMR_AC\\t1000Gp3_AMR_AF\\t1000Gp3_EAS_AC\\t1000Gp3_EAS_AF\\t1000Gp3_SAS_AC\\t1000Gp3_SAS_AF\\tTWINSUK_AC\\tTWINSUK_AF\\tALSPAC_AC\\tALSPAC_AF\\tESP6500_AA_AC\\tESP6500_AA_AF\\tESP6500_EA_AC\\tESP6500_EA_AF\\tExAC_AC\\tExAC_AF\\tExAC_Adj_AC\\tExAC_Adj_AF\\tExAC_AFR_AC\\tExAC_AFR_AF\\tExAC_AMR_AC\\tExAC_AMR_AF\\tExAC_EAS_AC\\tExAC_EAS_AF\\tExAC_FIN_AC\\tExAC_FIN_AF\\tExAC_NFE_AC\\tExAC_NFE_AF\\tExAC_SAS_AC\\tExAC_SAS_AF\\tExAC_nonTCGA_AC\\tExAC_nonTCGA_AF\\tExAC_nonTCGA_Adj_AC\\tExAC_nonTCGA_Adj_AF\\tExAC_nonTCGA_AFR_AC\\tExAC_nonTCGA_AFR_AF\\tExAC_nonTCGA_AMR_AC\\tExAC_nonTCGA_AMR_AF\\tExAC_nonTCGA_EAS_AC\\tExAC_nonTCGA_EAS_AF\\tExAC_nonTCGA_FIN_AC\\tExAC_nonTCGA_FIN_AF\\tExAC_nonTCGA_NFE_AC\\tExAC_nonTCGA_NFE_AF\\tExAC_nonTCGA_SAS_AC\\tExAC_nonTCGA_SAS_AF\\tExAC_nonpsych_AC\\tExAC_nonpsych_AF\\tExAC_nonpsych_Adj_AC\\tExAC_nonpsych_Adj_AF\\tExAC_nonpsych_AFR_AC\\tExAC_nonpsych_AFR_AF\\tExAC_nonpsych_AMR_AC\\tExAC_nonpsych_AMR_AF\\tExAC_nonpsych_EAS_AC\\tExAC_nonpsych_EAS_AF\\tExAC_nonpsych_FIN_AC\\tExAC_nonpsych_FIN_AF\\tExAC_nonpsych_NFE_AC\\tExAC_nonpsych_NFE_AF\\tExAC_nonpsych_SAS_AC\\tExAC_nonpsych_SAS_AF\\tRegulomeDB_motif\\tRegulomeDB_score\\tMotif_breaking\\tnetwork_hub\\tENCODE_annotated\\tsensitive\\tultra_sensitive\\ttarget_gene\\tfunseq_noncoding_score\\tfunseq2_noncoding_score\\tfunseq2_noncoding_rankscore\\tCADD_raw\\tCADD_phred\\tCADD_raw_rankscore\\tDANN_score\\tDANN_rank_score\\tfathmm-MKL_non-coding_score\\tfathmm-MKL_non-coding_rankscore\\tfathmm-MKL_non-coding_pred\\tfathmm-MKL_non-coding_group\\tfathmm-MKL_coding_score\\tfathmm-MKL_coding_rankscore\\tfathmm-MKL_coding_pred\\tfathmm-MKL_coding_group\\tEigen-raw\\tEigen-phred\\tEigen_coding_or_noncoding\\tEigen-raw_rankscore\\tEigen-PC-raw\\tEigen-PC-raw_rankscore\\tORegAnno_type\\tORegAnno_PMID\\tENCODE_TFBS\\tENCODE_TFBS_score\\tENCODE_TFBS_cells\\tENCODE_Dnase_score\\tENCODE_Dnase_cells\\tEnhancerFinder_general_developmental_enhancer\\tEnhancerFinder_brain_enhancer\\tEnhancerFinder_heart_enhancer\\tEnhancerFinder_limb_enhancer\\tSuperEnhancer_tissue_cell\\tSuperEnhancer_RefSeq_id\\tSuperEnhancer_Gene_symbol\\tFANTOM5_enhancer_permissive\\tFANTOM5_enhancer_robust\\tFANTOM5_enhancer_target\\tFANTOM5_enhancer_expressed_tissue_cell\\tFANTOM5_enhancer_differentially_expressed_tissue_cell\\tFANTOM5_CAGE_peak_permissive\\tFANTOM5_CAGE_peak_robust\\tEnsembl_Regulatory_Build_Overviews\\tEnsembl_Regulatory_Build_TFBS\\tEnsembl_Regulatory_Build_TFBS_prob\\taaref\\taaalt\\tgenename\\tUniprot_acc\\tUniprot_id\\tUniprot_aapos\\tInterpro_domain\\tcds_strand\\trefcodon\\tSLR_test_statistic \\tcodonpos\\tfold-degenerate\\tEnsembl_geneid\\tEnsembl_transcriptid\\taapos\\taapos_SIFT\\taapos_FATHMM\\tSIFT_score\\tSIFT_converted_rankscore\\tSIFT_pred\\tPolyphen2_HDIV_score\\tPolyphen2_HDIV_rankscore\\tPolyphen2_HDIV_pred\\tPolyphen2_HVAR_score\\tPolyphen2_HVAR_rankscore\\tPolyphen2_HVAR_pred\\tLRT_score\\tLRT_converted_rankscore\\tLRT_pred\\tMutationTaster_score\\tMutationTaster_converted_rankscore\\tMutationTaster_pred\\tMutationAssessor_score\\tMutationAssessor_rankscore\\tMutationAssessor_pred\\tFATHMM_score\\tFATHMM_rankscore\\tFATHMM_pred\\tMetaSVM_score\\tMetaSVM_rankscore\\tMetaSVM_pred\\tMetaLR_score\\tMetaLR_rankscore\\tMetaLR_pred\\tReliability_index\\tVEST3_score\\tVEST3_rankscore\\tPROVEAN_score\\tPROVEAN_converted_rankscore\\tPROVEAN_pred\\tANNOVAR_ensembl_precedent_consequence\\tANNOVAR_ensembl_precedent_gene\\tunique_variant&quot; ## [2] &quot;22\\t19055814\\tC\\tT\\tintronic|intronic|intronic|intronic\\tENST00000263196|ENST00000389262|ENST00000537045|ENST00000545799\\tENSG00000070413|ENSG00000070413|ENSG00000070413|ENSG00000070413\\t.|.|.|.\\t.|.|.|.\\t.|.|.|.\\t.|.|.|.\\tENSG00000070413(4):intronic(4)\\tintron_variant|intron_variant|upstream_gene_variant|intron_variant|intron_variant\\tMODIFIER|MODIFIER|MODIFIER|MODIFIER|MODIFIER\\tdomain:LDL-receptor_class_A|.|.|.|.\\tLOW|.|.|.|.\\tENST00000263196|ENST00000389262|ENST00000473832|ENST00000537045|ENST00000545799\\tprotein_coding|nonsense_mediated_decay|processed_transcript|protein_coding|protein_coding\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\tENSG00000070413|ENSG00000070413|ENSG00000070413|ENSG00000070413|ENSG00000070413\\tc.203-76G&gt;A|c.-851-76G&gt;A|n.-2397G&gt;A|c.80-76G&gt;A|c.203-76G&gt;A\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t2/9|2/10|.|1/8|2/10\\t.|.|2397|.|.\\t.|.|.|.|.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tDGCR2(7):intron_variant(4)upstream_gene_variant(1)\\tintron_variant|upstream_gene_variant|intron_variant|intron_variant,NMD_transcript_variant|intron_variant\\tENST00000537045|ENST00000473832|ENST00000263196|ENST00000389262|ENST00000545799\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\tENSG00000070413|ENSG00000070413|ENSG00000070413|ENSG00000070413|ENSG00000070413\\tENSP00000440062|.|ENSP00000263196|ENSP00000373914|ENSP00000445069\\tCCDS54496.1|.|CCDS33598.1|.|.\\tIDD_HUMAN|.|IDD_HUMAN|.|.\\t.|2397|.|.|.\\t.|.|.|.|.\\tENST00000537045.1:c.80-76G&gt;A|.|ENST00000263196.7:c.203-76G&gt;A|ENST00000389262.4:c.-851-76G&gt;A|ENST00000545799.1:c.203-76G&gt;A\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t1/8|.|2/9|2/10|2/10\\t-|-|-|-|-\\t.|.|YES|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\tDGCR2(7):intron_variant(3)intron_variant,NMD_transcript_variant(1)upstream_gene_variant(1)\\tintronic|intronic|intronic|intronic\\tNM_001173533|NM_001173534|NM_001184781|NM_005137\\tDGCR2|DGCR2|DGCR2|DGCR2\\t.|.|.|.\\t.|.|.|.\\t.|.|.|.\\t.|.|.|.\\tDGCR2(4):intronic(4)\\tintron_variant|intron_variant|intron_variant|intron_variant|intron_variant\\tMODIFIER|MODIFIER|MODIFIER|MODIFIER|MODIFIER\\t.|.|.|.|.\\t.|.|.|.|.\\tNM_001173533.1|NM_001173534.1|NM_001184781.1|NM_005137.2|NR_033674.1\\tprotein_coding|protein_coding|protein_coding|protein_coding|pseudogene\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\tc.80-76G&gt;A|c.80-76G&gt;A|c.203-76G&gt;A|c.203-76G&gt;A|n.328-76G&gt;A\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t1/8|1/8|2/9|2/9|1/8\\t.|.|.|.|.\\t.|.|.|.|.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tDGCR2(5):intron_variant(5)\\tintron_variant|intron_variant|intron_variant|intron_variant|intron_variant,non_coding_transcript_variant\\tNM_001173534.1|NM_001184781.1|NM_001173533.1|NM_005137.2|NR_033674.1\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\t9993|9993|9993|9993|9993\\tNP_001167005.1|NP_001171710.1|NP_001167004.1|NP_005128.1|.\\t.|.|.|.|.\\t.|.|.|.|.\\tNM_001173534.1:c.80-76G&gt;A|NM_001184781.1:c.203-76G&gt;A|NM_001173533.1:c.80-76G&gt;A|NM_005137.2:c.203-76G&gt;A|NR_033674.1:n.328-76G&gt;A\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t1/8|2/9|1/8|2/9|1/8\\t-|-|-|-|-\\t.|.|.|YES|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\t.|.|.|.|.\\tDGCR2(5):intron_variant(4)intron_variant,non_coding_transcript_variant(1)\\tintronic|intronic|intronic|intronic|intronic|intronic\\tuc002zoq.1|uc002zor.1|uc011agr.1|uc021wkx.1|uc021wky.1|uc021wkz.1\\tDGCR2|DGCR2|DGCR2|DGCR2|DGCR2|DGCR2\\t.|.|.|.|.|.\\t.|.|.|.|.|.\\t.|.|.|.|.|.\\t.|.|.|.|.|.\\tDGCR2(6):intronic(6)\\trs546724885\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t1.0\\t1.0\\t0.99285716\\t1.0\\t98.9773\\t98.9998\\tY\\tN\\tC\\tC/C\\tC/C\\t-1.193\\t0.05127\\t-0.915\\t0.09469\\t-0.133\\t0.32678\\t0.001\\t0.05886\\t0.000\\t0.14292\\t0.000\\t0.16763\\t3.71\\t-3.62\\t0.06162\\t7.0802\\t0.86688\\t0.084033\\t0.81986\\t0\\t0.047999\\t0.00538\\t0\\t0.081037\\t0.85223\\t0\\t0.089874\\t0.86623\\t0\\t0.998263009421969\\t0.82144\\t1\\t1.9968051118210862E-4\\t1\\t7.564296520423601E-4\\t0\\t0.0\\t0\\t0.0\\t0\\t0.0\\t0\\t0.0\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tChromatin_Structure|DNase-seq\\t5\\t.\\t.\\tDHS(MCV-5|chr22:19055665-19055815)\\t.\\t.\\t.\\t1\\t1.47702766604517\\t0.97241\\t-0.086269\\t1.834\\t0.34517\\t0.47717823829120337\\t0.25900\\t0.06740\\t0.15147\\tN\\tADB\\t0.00030\\t0.00848\\tN\\tAEFDBI\\t-0.118960630637635\\t3.27754\\tn\\t0.52812\\t0.302794242594935\\t0.92771\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tN\\tN\\tN\\tN\\t.\\t.\\t.\\tN\\tN\\t.\\t.\\t.\\tN\\tN\\topen\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\t.\\tintronic\\tDGCR2\\tY&quot; The DCC has begun an R package, wgsaparsr, to begin working with WGSA output files. This package is under development, and is available on github at https://github.com/UW-GAC/wgsaparsr. For now, the package can be installed from github using the devtools package: library(devtools) devtools::install_github(&quot;UW-GAC/wgsaparsr@1.0.0.9003&quot;) library(wgsaparsr) #library(tidyverse) # just in case it&#39;s not loaded yet library(tibble) library(dplyr) library(tidyr) library(readr) wgsaparsr includes a get_fields() function to list the annotation fields available in a WGSA output file: # list all fields in an annotation file: get_fields(&quot;snp.tsv.gz&quot;) ## [1] &quot;#chr&quot; ## [2] &quot;pos&quot; ## [3] &quot;ref&quot; ## [4] &quot;alt&quot; ## [5] &quot;ANNOVAR_ensembl_Effect&quot; ## [6] &quot;ANNOVAR_ensembl_Transcript_ID&quot; ## [7] &quot;ANNOVAR_ensembl_Gene_ID&quot; ## [8] &quot;ANNOVAR_ensembl_Closest_gene(intergenic_only)&quot; ## [9] &quot;ANNOVAR_ensembl_HGVSc&quot; ## [10] &quot;ANNOVAR_ensembl_HGVSp&quot; ## [11] &quot;ANNOVAR_ensembl_Exon_Rank&quot; ## [12] &quot;ANNOVAR_ensembl_summary&quot; ## [13] &quot;SnpEff_ensembl_Effect&quot; ## [14] &quot;SnpEff_ensembl_Effect_impact&quot; ## [15] &quot;SnpEff_ensembl_Sequence_feature&quot; ## [16] &quot;SnpEff_ensembl_Sequence_feature_impact&quot; ## [17] &quot;SnpEff_ensembl_Transcript_ID&quot; ## [18] &quot;SnpEff_ensembl_Transcript_biotype&quot; ## [19] &quot;SnpEff_ensembl_Gene_name&quot; ## [20] &quot;SnpEff_ensembl_Gene_ID&quot; ## [21] &quot;SnpEff_ensembl_HGVSc&quot; ## [22] &quot;SnpEff_ensembl_HGVSp&quot; ## [23] &quot;SnpEff_ensembl_Protein_position/Protein_len&quot; ## [24] &quot;SnpEff_ensembl_CDS_position/CDS_len&quot; ## [25] &quot;SnpEff_ensembl_cDNA_position/cDNA_len&quot; ## [26] &quot;SnpEff_ensembl_Exon_or_intron_rank/total&quot; ## [27] &quot;SnpEff_ensembl_Distance_to_feature&quot; ## [28] &quot;SnpEff_ensembl_Warnings&quot; ## [29] &quot;SnpEff_ensembl_LOF/NMD&quot; ## [30] &quot;SnpEff_ensembl_LOF/NMD_gene_name&quot; ## [31] &quot;SnpEff_ensembl_LOF/NMD_gene_ID&quot; ## [32] &quot;SnpEff_ensembl_LOF/NMD_num_transcripts_affected&quot; ## [33] &quot;SnpEff_ensembl_LOF/NMD_percent_transcripts_affected&quot; ## [34] &quot;SnpEff_ensembl_TF_binding_effect&quot; ## [35] &quot;SnpEff_ensembl_TF_name&quot; ## [36] &quot;SnpEff_ensembl_TF_ID&quot; ## [37] &quot;SnpEff_ensembl_summary&quot; ## [38] &quot;VEP_ensembl_Consequence&quot; ## [39] &quot;VEP_ensembl_Transcript_ID&quot; ## [40] &quot;VEP_ensembl_Gene_Name&quot; ## [41] &quot;VEP_ensembl_Gene_ID&quot; ## [42] &quot;VEP_ensembl_Protein_ID&quot; ## [43] &quot;VEP_ensembl_CCDS&quot; ## [44] &quot;VEP_ensembl_SWISSPROT&quot; ## [45] &quot;VEP_ensembl_Codon_Change_or_Distance&quot; ## [46] &quot;VEP_ensembl_Amino_Acid_Change&quot; ## [47] &quot;VEP_ensembl_HGVSc&quot; ## [48] &quot;VEP_ensembl_HGVSp&quot; ## [49] &quot;VEP_ensembl_cDNA_position&quot; ## [50] &quot;VEP_ensembl_CDS_position&quot; ## [51] &quot;VEP_ensembl_Protein_position&quot; ## [52] &quot;VEP_ensembl_Exon_or_Intron_Rank&quot; ## [53] &quot;VEP_ensembl_STRAND&quot; ## [54] &quot;VEP_ensembl_CANONICAL&quot; ## [55] &quot;VEP_ensembl_LoF&quot; ## [56] &quot;VEP_ensembl_LoF_filter&quot; ## [57] &quot;VEP_ensembl_LoF_flags&quot; ## [58] &quot;VEP_ensembl_LoF_info&quot; ## [59] &quot;VEP_ensembl_summary&quot; ## [60] &quot;ANNOVAR_refseq_Effect&quot; ## [61] &quot;ANNOVAR_refseq_Transcript_ID&quot; ## [62] &quot;ANNOVAR_refseq_Gene_ID&quot; ## [63] &quot;ANNOVAR_refseq_Closest_gene(intergenic_only)&quot; ## [64] &quot;ANNOVAR_refseq_HGVSc&quot; ## [65] &quot;ANNOVAR_refseq_HGVSp&quot; ## [66] &quot;ANNOVAR_refseq_Exon_Rank&quot; ## [67] &quot;ANNOVAR_refseq_summary&quot; ## [68] &quot;SnpEff_refseq_Effect&quot; ## [69] &quot;SnpEff_refseq_Effect_impact&quot; ## [70] &quot;SnpEff_refseq_Sequence_feature&quot; ## [71] &quot;SnpEff_refseq_Sequence_feature_impact&quot; ## [72] &quot;SnpEff_refseq_Transcript_ID&quot; ## [73] &quot;SnpEff_refseq_Transcript_biotype&quot; ## [74] &quot;SnpEff_refseq_Gene_name&quot; ## [75] &quot;SnpEff_refseq_Gene_ID&quot; ## [76] &quot;SnpEff_refseq_HGVSc&quot; ## [77] &quot;SnpEff_refseq_HGVSp&quot; ## [78] &quot;SnpEff_refseq_Protein_position/Protein_len&quot; ## [79] &quot;SnpEff_refseq_CDS_position/CDS_len&quot; ## [80] &quot;SnpEff_refseq_cDNA_position/cDNA_len&quot; ## [81] &quot;SnpEff_refseq_Exon_or_intron_rank/total&quot; ## [82] &quot;SnpEff_refseq_Distance_to_feature&quot; ## [83] &quot;SnpEff_refseq_Warnings&quot; ## [84] &quot;SnpEff_refseq_LOF/NMD&quot; ## [85] &quot;SnpEff_refseq_LOF/NMD_gene_name&quot; ## [86] &quot;SnpEff_refseq_LOF/NMD_gene_ID&quot; ## [87] &quot;SnpEff_refseq_LOF/NMD_num_transcripts_affected&quot; ## [88] &quot;SnpEff_refseq_LOF/NMD_percent_transcripts_affected&quot; ## [89] &quot;SnpEff_refseq_TF_binding_effect&quot; ## [90] &quot;SnpEff_refseq_TF_name&quot; ## [91] &quot;SnpEff_refseq_TF_ID&quot; ## [92] &quot;SnpEff_refseq_summary&quot; ## [93] &quot;VEP_refseq_Consequence&quot; ## [94] &quot;VEP_refseq_Transcript_ID&quot; ## [95] &quot;VEP_refseq_Gene_Name&quot; ## [96] &quot;VEP_refseq_Gene_ID&quot; ## [97] &quot;VEP_refseq_Protein_ID&quot; ## [98] &quot;VEP_refseq_Codon_Change_or_Distance&quot; ## [99] &quot;VEP_refseq_Amino_Acid_Change&quot; ## [100] &quot;VEP_refseq_HGVSc&quot; ## [101] &quot;VEP_refseq_HGVSp&quot; ## [102] &quot;VEP_refseq_cDNA_position&quot; ## [103] &quot;VEP_refseq_CDS_position&quot; ## [104] &quot;VEP_refseq_Protein_position&quot; ## [105] &quot;VEP_refseq_Exon_or_Intron_Rank&quot; ## [106] &quot;VEP_refseq_STRAND&quot; ## [107] &quot;VEP_refseq_CANONICAL&quot; ## [108] &quot;VEP_refseq_LoF&quot; ## [109] &quot;VEP_refseq_LoF_filter&quot; ## [110] &quot;VEP_refseq_LoF_flags&quot; ## [111] &quot;VEP_refseq_LoF_info&quot; ## [112] &quot;VEP_refseq_summary&quot; ## [113] &quot;ANNOVAR_ucsc_Effect&quot; ## [114] &quot;ANNOVAR_ucsc_Transcript_ID&quot; ## [115] &quot;ANNOVAR_ucsc_Gene_ID&quot; ## [116] &quot;ANNOVAR_ucsc_Closest_gene(intergenic_only)&quot; ## [117] &quot;ANNOVAR_ucsc_HGVSc&quot; ## [118] &quot;ANNOVAR_ucsc_HGVSp&quot; ## [119] &quot;ANNOVAR_ucsc_Exon_Rank&quot; ## [120] &quot;ANNOVAR_ucsc_summary&quot; ## [121] &quot;rs_dbSNP147&quot; ## [122] &quot;sno_miRNA_name&quot; ## [123] &quot;sno_miRNA_type&quot; ## [124] &quot;UTR3_miRNA_target&quot; ## [125] &quot;TargetScan_context++_score_percentile&quot; ## [126] &quot;splicing_consensus_ada_score&quot; ## [127] &quot;splicing_consensus_rf_score&quot; ## [128] &quot;GWAS_catalog_rs&quot; ## [129] &quot;GWAS_catalog_trait&quot; ## [130] &quot;GWAS_catalog_pubmedid&quot; ## [131] &quot;GRASP_rs&quot; ## [132] &quot;GRASP_PMID&quot; ## [133] &quot;GRASP_p-value&quot; ## [134] &quot;GRASP_phenotype&quot; ## [135] &quot;GRASP_ancestry&quot; ## [136] &quot;GRASP_platform&quot; ## [137] &quot;clinvar_rs&quot; ## [138] &quot;clinvar_clnsig&quot; ## [139] &quot;clinvar_trait&quot; ## [140] &quot;clinvar_golden_stars&quot; ## [141] &quot;GTEx_V6_gene&quot; ## [142] &quot;GTEx_V6_tissue&quot; ## [143] &quot;MAP20&quot; ## [144] &quot;MAP35&quot; ## [145] &quot;MAP20(+-149bp)&quot; ## [146] &quot;MAP35(+-149bp)&quot; ## [147] &quot;GMS_single-end&quot; ## [148] &quot;GMS_paired-end&quot; ## [149] &quot;1000G_strict_masked&quot; ## [150] &quot;RepeatMasker_masked&quot; ## [151] &quot;Ancestral_allele&quot; ## [152] &quot;AltaiNeandertal&quot; ## [153] &quot;Denisova&quot; ## [154] &quot;phyloP46way_primate&quot; ## [155] &quot;phyloP46way_primate_rankscore&quot; ## [156] &quot;phyloP46way_placental&quot; ## [157] &quot;phyloP46way_placental_rankscore&quot; ## [158] &quot;phyloP100way_vertebrate&quot; ## [159] &quot;phyloP100way_vertebrate_rankscore&quot; ## [160] &quot;phastCons46way_primate&quot; ## [161] &quot;phastCons46way_primate_rankscore&quot; ## [162] &quot;phastCons46way_placental&quot; ## [163] &quot;phastCons46way_placental_rankscore&quot; ## [164] &quot;phastCons100way_vertebrate&quot; ## [165] &quot;phastCons100way_vertebrate_rankscore&quot; ## [166] &quot;GERP_NR&quot; ## [167] &quot;GERP_RS&quot; ## [168] &quot;GERP_RS_rankscore&quot; ## [169] &quot;SiPhy_29way_logOdds&quot; ## [170] &quot;SiPhy_29way_logOdds_rankscore&quot; ## [171] &quot;integrated_fitCons_score&quot; ## [172] &quot;integrated_fitCons_rankscore&quot; ## [173] &quot;integrated_confidence_value&quot; ## [174] &quot;GM12878_fitCons_score&quot; ## [175] &quot;GM12878_fitCons_rankscore&quot; ## [176] &quot;GM12878_confidence_value&quot; ## [177] &quot;H1-hESC_fitCons_score&quot; ## [178] &quot;H1-hESC_fitCons_rankscore&quot; ## [179] &quot;H1-hESC_confidence_value&quot; ## [180] &quot;HUVEC_fitCons_score&quot; ## [181] &quot;HUVEC_fitCons_rankscore&quot; ## [182] &quot;HUVEC_confidence_value&quot; ## [183] &quot;GenoCanyon_score&quot; ## [184] &quot;GenoCanyon_rankscore&quot; ## [185] &quot;1000Gp3_AC&quot; ## [186] &quot;1000Gp3_AF&quot; ## [187] &quot;1000Gp3_AFR_AC&quot; ## [188] &quot;1000Gp3_AFR_AF&quot; ## [189] &quot;1000Gp3_EUR_AC&quot; ## [190] &quot;1000Gp3_EUR_AF&quot; ## [191] &quot;1000Gp3_AMR_AC&quot; ## [192] &quot;1000Gp3_AMR_AF&quot; ## [193] &quot;1000Gp3_EAS_AC&quot; ## [194] &quot;1000Gp3_EAS_AF&quot; ## [195] &quot;1000Gp3_SAS_AC&quot; ## [196] &quot;1000Gp3_SAS_AF&quot; ## [197] &quot;TWINSUK_AC&quot; ## [198] &quot;TWINSUK_AF&quot; ## [199] &quot;ALSPAC_AC&quot; ## [200] &quot;ALSPAC_AF&quot; ## [201] &quot;ESP6500_AA_AC&quot; ## [202] &quot;ESP6500_AA_AF&quot; ## [203] &quot;ESP6500_EA_AC&quot; ## [204] &quot;ESP6500_EA_AF&quot; ## [205] &quot;ExAC_AC&quot; ## [206] &quot;ExAC_AF&quot; ## [207] &quot;ExAC_Adj_AC&quot; ## [208] &quot;ExAC_Adj_AF&quot; ## [209] &quot;ExAC_AFR_AC&quot; ## [210] &quot;ExAC_AFR_AF&quot; ## [211] &quot;ExAC_AMR_AC&quot; ## [212] &quot;ExAC_AMR_AF&quot; ## [213] &quot;ExAC_EAS_AC&quot; ## [214] &quot;ExAC_EAS_AF&quot; ## [215] &quot;ExAC_FIN_AC&quot; ## [216] &quot;ExAC_FIN_AF&quot; ## [217] &quot;ExAC_NFE_AC&quot; ## [218] &quot;ExAC_NFE_AF&quot; ## [219] &quot;ExAC_SAS_AC&quot; ## [220] &quot;ExAC_SAS_AF&quot; ## [221] &quot;ExAC_nonTCGA_AC&quot; ## [222] &quot;ExAC_nonTCGA_AF&quot; ## [223] &quot;ExAC_nonTCGA_Adj_AC&quot; ## [224] &quot;ExAC_nonTCGA_Adj_AF&quot; ## [225] &quot;ExAC_nonTCGA_AFR_AC&quot; ## [226] &quot;ExAC_nonTCGA_AFR_AF&quot; ## [227] &quot;ExAC_nonTCGA_AMR_AC&quot; ## [228] &quot;ExAC_nonTCGA_AMR_AF&quot; ## [229] &quot;ExAC_nonTCGA_EAS_AC&quot; ## [230] &quot;ExAC_nonTCGA_EAS_AF&quot; ## [231] &quot;ExAC_nonTCGA_FIN_AC&quot; ## [232] &quot;ExAC_nonTCGA_FIN_AF&quot; ## [233] &quot;ExAC_nonTCGA_NFE_AC&quot; ## [234] &quot;ExAC_nonTCGA_NFE_AF&quot; ## [235] &quot;ExAC_nonTCGA_SAS_AC&quot; ## [236] &quot;ExAC_nonTCGA_SAS_AF&quot; ## [237] &quot;ExAC_nonpsych_AC&quot; ## [238] &quot;ExAC_nonpsych_AF&quot; ## [239] &quot;ExAC_nonpsych_Adj_AC&quot; ## [240] &quot;ExAC_nonpsych_Adj_AF&quot; ## [241] &quot;ExAC_nonpsych_AFR_AC&quot; ## [242] &quot;ExAC_nonpsych_AFR_AF&quot; ## [243] &quot;ExAC_nonpsych_AMR_AC&quot; ## [244] &quot;ExAC_nonpsych_AMR_AF&quot; ## [245] &quot;ExAC_nonpsych_EAS_AC&quot; ## [246] &quot;ExAC_nonpsych_EAS_AF&quot; ## [247] &quot;ExAC_nonpsych_FIN_AC&quot; ## [248] &quot;ExAC_nonpsych_FIN_AF&quot; ## [249] &quot;ExAC_nonpsych_NFE_AC&quot; ## [250] &quot;ExAC_nonpsych_NFE_AF&quot; ## [251] &quot;ExAC_nonpsych_SAS_AC&quot; ## [252] &quot;ExAC_nonpsych_SAS_AF&quot; ## [253] &quot;RegulomeDB_motif&quot; ## [254] &quot;RegulomeDB_score&quot; ## [255] &quot;Motif_breaking&quot; ## [256] &quot;network_hub&quot; ## [257] &quot;ENCODE_annotated&quot; ## [258] &quot;sensitive&quot; ## [259] &quot;ultra_sensitive&quot; ## [260] &quot;target_gene&quot; ## [261] &quot;funseq_noncoding_score&quot; ## [262] &quot;funseq2_noncoding_score&quot; ## [263] &quot;funseq2_noncoding_rankscore&quot; ## [264] &quot;CADD_raw&quot; ## [265] &quot;CADD_phred&quot; ## [266] &quot;CADD_raw_rankscore&quot; ## [267] &quot;DANN_score&quot; ## [268] &quot;DANN_rank_score&quot; ## [269] &quot;fathmm-MKL_non-coding_score&quot; ## [270] &quot;fathmm-MKL_non-coding_rankscore&quot; ## [271] &quot;fathmm-MKL_non-coding_pred&quot; ## [272] &quot;fathmm-MKL_non-coding_group&quot; ## [273] &quot;fathmm-MKL_coding_score&quot; ## [274] &quot;fathmm-MKL_coding_rankscore&quot; ## [275] &quot;fathmm-MKL_coding_pred&quot; ## [276] &quot;fathmm-MKL_coding_group&quot; ## [277] &quot;Eigen-raw&quot; ## [278] &quot;Eigen-phred&quot; ## [279] &quot;Eigen_coding_or_noncoding&quot; ## [280] &quot;Eigen-raw_rankscore&quot; ## [281] &quot;Eigen-PC-raw&quot; ## [282] &quot;Eigen-PC-raw_rankscore&quot; ## [283] &quot;ORegAnno_type&quot; ## [284] &quot;ORegAnno_PMID&quot; ## [285] &quot;ENCODE_TFBS&quot; ## [286] &quot;ENCODE_TFBS_score&quot; ## [287] &quot;ENCODE_TFBS_cells&quot; ## [288] &quot;ENCODE_Dnase_score&quot; ## [289] &quot;ENCODE_Dnase_cells&quot; ## [290] &quot;EnhancerFinder_general_developmental_enhancer&quot; ## [291] &quot;EnhancerFinder_brain_enhancer&quot; ## [292] &quot;EnhancerFinder_heart_enhancer&quot; ## [293] &quot;EnhancerFinder_limb_enhancer&quot; ## [294] &quot;SuperEnhancer_tissue_cell&quot; ## [295] &quot;SuperEnhancer_RefSeq_id&quot; ## [296] &quot;SuperEnhancer_Gene_symbol&quot; ## [297] &quot;FANTOM5_enhancer_permissive&quot; ## [298] &quot;FANTOM5_enhancer_robust&quot; ## [299] &quot;FANTOM5_enhancer_target&quot; ## [300] &quot;FANTOM5_enhancer_expressed_tissue_cell&quot; ## [301] &quot;FANTOM5_enhancer_differentially_expressed_tissue_cell&quot; ## [302] &quot;FANTOM5_CAGE_peak_permissive&quot; ## [303] &quot;FANTOM5_CAGE_peak_robust&quot; ## [304] &quot;Ensembl_Regulatory_Build_Overviews&quot; ## [305] &quot;Ensembl_Regulatory_Build_TFBS&quot; ## [306] &quot;Ensembl_Regulatory_Build_TFBS_prob&quot; ## [307] &quot;aaref&quot; ## [308] &quot;aaalt&quot; ## [309] &quot;genename&quot; ## [310] &quot;Uniprot_acc&quot; ## [311] &quot;Uniprot_id&quot; ## [312] &quot;Uniprot_aapos&quot; ## [313] &quot;Interpro_domain&quot; ## [314] &quot;cds_strand&quot; ## [315] &quot;refcodon&quot; ## [316] &quot;SLR_test_statistic &quot; ## [317] &quot;codonpos&quot; ## [318] &quot;fold-degenerate&quot; ## [319] &quot;Ensembl_geneid&quot; ## [320] &quot;Ensembl_transcriptid&quot; ## [321] &quot;aapos&quot; ## [322] &quot;aapos_SIFT&quot; ## [323] &quot;aapos_FATHMM&quot; ## [324] &quot;SIFT_score&quot; ## [325] &quot;SIFT_converted_rankscore&quot; ## [326] &quot;SIFT_pred&quot; ## [327] &quot;Polyphen2_HDIV_score&quot; ## [328] &quot;Polyphen2_HDIV_rankscore&quot; ## [329] &quot;Polyphen2_HDIV_pred&quot; ## [330] &quot;Polyphen2_HVAR_score&quot; ## [331] &quot;Polyphen2_HVAR_rankscore&quot; ## [332] &quot;Polyphen2_HVAR_pred&quot; ## [333] &quot;LRT_score&quot; ## [334] &quot;LRT_converted_rankscore&quot; ## [335] &quot;LRT_pred&quot; ## [336] &quot;MutationTaster_score&quot; ## [337] &quot;MutationTaster_converted_rankscore&quot; ## [338] &quot;MutationTaster_pred&quot; ## [339] &quot;MutationAssessor_score&quot; ## [340] &quot;MutationAssessor_rankscore&quot; ## [341] &quot;MutationAssessor_pred&quot; ## [342] &quot;FATHMM_score&quot; ## [343] &quot;FATHMM_rankscore&quot; ## [344] &quot;FATHMM_pred&quot; ## [345] &quot;MetaSVM_score&quot; ## [346] &quot;MetaSVM_rankscore&quot; ## [347] &quot;MetaSVM_pred&quot; ## [348] &quot;MetaLR_score&quot; ## [349] &quot;MetaLR_rankscore&quot; ## [350] &quot;MetaLR_pred&quot; ## [351] &quot;Reliability_index&quot; ## [352] &quot;VEST3_score&quot; ## [353] &quot;VEST3_rankscore&quot; ## [354] &quot;PROVEAN_score&quot; ## [355] &quot;PROVEAN_converted_rankscore&quot; ## [356] &quot;PROVEAN_pred&quot; ## [357] &quot;ANNOVAR_ensembl_precedent_consequence&quot; ## [358] &quot;ANNOVAR_ensembl_precedent_gene&quot; ## [359] &quot;unique_variant&quot; Only a subset of these annotations may be necessary for a particular association test, and it is unweildy to work with all of them, so it is useful to process the WGSA output file to select fields of interest. The wgsaparsr function parse_to_file() allows field selection by name. An additional complication in working with the WGSA output files is that some of the annotation fields are transcript-based, rather than position-based. Thus, if a variant locus is within multiple transcripts, those fields will have multiple entries (often separated by a | character). For example, annotation fields such as VEP_ensembl_Transcript_ID may have many values within a single tab-separated field. wgsaparsr::parse_to_file() addresses this by splitting such list-fields into multiple rows. Other annotation fields for that variant are duplicated, and associated columns are filled with the same value for each transcript that a particular variant falls within. A consequence of this approach is that the processed annotation file has more lines than the WGSA output file. In freeze 4, processing expanded the annotation by a factor of about 5 - the 220 million annotations result in a 1-billion row database for subsequent aggregation. wgsaparsr::parse_to_file() reads a snp annotation file, selects specified fields, and expands user-defined transcript-level annotation fields. It produces a tab-separated output file for subsequent analysis. desired_columns &lt;- c( &quot;`#chr`&quot;, #NOTE: backtics on #chr because it starts with special character! &quot;pos&quot;, &quot;ref&quot;, &quot;alt&quot;, &quot;rs_dbSNP147&quot;, # &quot;CADDphred&quot;, &quot;CADD_phred&quot;, #NOTE: different than the indel annotation file. &quot;VEP_ensembl_Transcript_ID&quot;, &quot;VEP_ensembl_Gene_Name&quot;, &quot;VEP_ensembl_Gene_ID&quot;, &quot;VEP_ensembl_Consequence&quot;, &quot;VEP_ensembl_Amino_Acid_Change&quot;, &quot;VEP_ensembl_LoF&quot;, &quot;VEP_ensembl_LoF_filter&quot;, &quot;VEP_ensembl_LoF_flags&quot;, &quot;VEP_ensembl_LoF_info&quot; # &quot;1000Gp3_AF&quot; #skipped for the workshop because code doesn&#39;t work with this variable name ) to_split &lt;- c( &quot;VEP_ensembl_Consequence&quot;, &quot;VEP_ensembl_Transcript_ID&quot;, &quot;VEP_ensembl_Gene_Name&quot;, &quot;VEP_ensembl_Gene_ID&quot;, &quot;VEP_ensembl_Amino_Acid_Change&quot;, &quot;VEP_ensembl_LoF&quot;, &quot;VEP_ensembl_LoF_filter&quot;, &quot;VEP_ensembl_LoF_flags&quot;, &quot;VEP_ensembl_LoF_info&quot; ) parse_to_file(&quot;snp.tsv.gz&quot;, &quot;parsed_snp.tsv&quot;, desired_columns, to_split, verbose = TRUE) ## [1] &quot;Chunks: 1 Lines: &lt;= 10000 Records in current import: 4134&quot; Although the output file has fewer columns than the the raw WGSA output file, this .tsv file is not particularly nice to work with in R: readLines(&quot;parsed_snp.tsv&quot;, n=2) ## [1] &quot;chr\\tpos\\tref\\talt\\trs_dbSNP147\\tCADD_phred\\tVEP_ensembl_Consequence\\tVEP_ensembl_Transcript_ID\\tVEP_ensembl_Gene_Name\\tVEP_ensembl_Gene_ID\\tVEP_ensembl_Amino_Acid_Change\\tVEP_ensembl_LoF\\tVEP_ensembl_LoF_filter\\tVEP_ensembl_LoF_flags\\tVEP_ensembl_LoF_info&quot; ## [2] &quot;22\\t19055814\\tC\\tT\\trs546724885\\t1.834\\tintron_variant\\tENST00000537045\\tDGCR2\\tENSG00000070413\\t.\\t.\\t.\\t.\\t.&quot; However, get_fields() does work on the parsed file to view available fields: # list all fields in an annotation file: get_fields(&quot;parsed_snp.tsv&quot;) ## [1] &quot;chr&quot; &quot;pos&quot; ## [3] &quot;ref&quot; &quot;alt&quot; ## [5] &quot;rs_dbSNP147&quot; &quot;CADD_phred&quot; ## [7] &quot;VEP_ensembl_Consequence&quot; &quot;VEP_ensembl_Transcript_ID&quot; ## [9] &quot;VEP_ensembl_Gene_Name&quot; &quot;VEP_ensembl_Gene_ID&quot; ## [11] &quot;VEP_ensembl_Amino_Acid_Change&quot; &quot;VEP_ensembl_LoF&quot; ## [13] &quot;VEP_ensembl_LoF_filter&quot; &quot;VEP_ensembl_LoF_flags&quot; ## [15] &quot;VEP_ensembl_LoF_info&quot; The WGSA output files for indel variants differs from the output for SNPs. Some of the field names differ slightly (e.g. “CADDphred” instead of “CADD_phred”), and there are some fields of interest that include feature counts in brackets (e.g. ENCODE_Dnase_cells includes fields like 125{23}). Thus, (for now) wgsaparsr includes parse_indel_to_file(). parse_indel_to_file() is very similar to parse_to_file(), and will likely be incorporated to that function in the near future. The syntax for parse_indel_to_file() is the same as parse_to_file(): desired_columns_indel &lt;- c( &quot;`#chr`&quot;, #NOTE: backtics on #chr because it starts with special character! &quot;pos&quot;, &quot;ref&quot;, &quot;alt&quot;, &quot;rs_dbSNP147&quot;, &quot;CADDphred&quot;, # &quot;CADD_phred&quot;, #NOTE: different than the general annotation file. &quot;VEP_ensembl_Transcript_ID&quot;, &quot;VEP_ensembl_Gene_Name&quot;, &quot;VEP_ensembl_Gene_ID&quot;, &quot;VEP_ensembl_Consequence&quot;, &quot;VEP_ensembl_Amino_Acid_Change&quot;, &quot;VEP_ensembl_LoF&quot;, &quot;VEP_ensembl_LoF_filter&quot;, &quot;VEP_ensembl_LoF_flags&quot;, &quot;VEP_ensembl_LoF_info&quot; # &quot;1000Gp3_AF&quot;#skipped for the workshop because code doesn&#39;t work with this variable name ) parse_indel_to_file(&quot;indel.tsv.gz&quot;, &quot;parsed_indel.tsv&quot;, desired_columns_indel, to_split, verbose = TRUE) ## [1] &quot;Chunks: 1 Lines: &lt;= 10000 Records in current import: 1024&quot; Inspection shows that the output format is the same for this function: readLines(&quot;parsed_indel.tsv&quot;, n=2) ## [1] &quot;chr\\tpos\\tref\\talt\\trs_dbSNP147\\tCADDphred\\tVEP_ensembl_Consequence\\tVEP_ensembl_Transcript_ID\\tVEP_ensembl_Gene_Name\\tVEP_ensembl_Gene_ID\\tVEP_ensembl_Amino_Acid_Change\\tVEP_ensembl_LoF\\tVEP_ensembl_LoF_filter\\tVEP_ensembl_LoF_flags\\tVEP_ensembl_LoF_info&quot; ## [2] &quot;22\\t24215519\\tC\\tCGCGTGTGT\\t.\\t0.977\\tintron_variant,non_coding_transcript_variant\\tENST00000405286\\tSLC2A11\\tENSG00000133460\\t.\\t.\\t.\\t.\\t.&quot; Or as a list, # list all fields in an annotation file: get_fields(&quot;parsed_indel.tsv&quot;) ## [1] &quot;chr&quot; &quot;pos&quot; ## [3] &quot;ref&quot; &quot;alt&quot; ## [5] &quot;rs_dbSNP147&quot; &quot;CADDphred&quot; ## [7] &quot;VEP_ensembl_Consequence&quot; &quot;VEP_ensembl_Transcript_ID&quot; ## [9] &quot;VEP_ensembl_Gene_Name&quot; &quot;VEP_ensembl_Gene_ID&quot; ## [11] &quot;VEP_ensembl_Amino_Acid_Change&quot; &quot;VEP_ensembl_LoF&quot; ## [13] &quot;VEP_ensembl_LoF_filter&quot; &quot;VEP_ensembl_LoF_flags&quot; ## [15] &quot;VEP_ensembl_LoF_info&quot; If an analyst wished to filter the list of variants prior to aggregation, the processing code could be modified to apply filters during parsing, or the annotation file could be reprocessed to apply filters at this point. Alternatively, filters can also be applied subsequent to aggregation. As insurance for this exercise, the parsed files are also available on github: ben.workshop.path &lt;- &quot;https://github.com/bheavner/topmed_workshop_2017_bh/raw/master&quot; parsedsnpfile &lt;- &quot;parsed_snp.tsv&quot; if (!file.exists(parsedsnpfile)) download.file(file.path(ben.workshop.path, parsedsnpfile), parsedsnpfile) parsedindelfile &lt;- &quot;parsed_indel.tsv&quot; if (!file.exists(parsedindelfile)) download.file(file.path(ben.workshop.path, parsedindelfile), parsedindelfile) 7.5.2 Defining “gene” ranges for aggregation Aggregation requires definition of the desired aggregation units. As a relatively simple example, we will build a list of genomic ranges corresponding to genes as defined by the GENCODE Project. The GENCODE Project’s Genomic ENCylopedia Of DNA Elements is available in the well-documented .gtf file format. Generally, .gtf files consist of 9 tab-separated fields, some of which may consist of various numbers of key:value pairs. The DCC has begun an R package, genetable, to parse and work with .gtf files. This package is under development, and is available on github at https://github.com/UW-GAC/genetable. For now, the package can be installed from github using the devtools package: #library(devtools) devtools::install_github(&quot;UW-GAC/genetable&quot;) library(genetable) I’ll be working with the gencode release 19 because it’s the last one on GRCh37. The file can be downloaded via https://www.gencodegenes.org/releases/19.html. In this case, I’ve trimmed the gencode file to include only chromosome 22 feature definitions (since that’s the variant annotation set I’m using for the demo). gtffile &lt;- &quot;chr22.gtf.gz&quot; if (!file.exists(gtffile)) download.file(file.path(ben.workshop.path, gtffile), gtffile) gtf_source &lt;- &quot;chr22.gtf.gz&quot; The details of the genetable package are of less interest for this workshop, so we’ll just use it - we can import and tidy the .gtf file: # import the gtf file to a tidy data frame (a tibble) gtf &lt;- import_gencode(gtf_source) # look at the tibble glimpse(gtf) ## Observations: 119,455 ## Variables: 30 ## $ seqname &lt;chr&gt; &quot;chr22&quot;, &quot;chr22&quot;, &quot;chr22&quot;, &quot;c... ## $ source &lt;chr&gt; &quot;HAVANA&quot;, &quot;HAVANA&quot;, &quot;HAVANA&quot;,... ## $ feature &lt;chr&gt; &quot;gene&quot;, &quot;transcript&quot;, &quot;exon&quot;,... ## $ start &lt;int&gt; 16062157, 16062157, 16062157,... ## $ end &lt;int&gt; 16063236, 16063236, 16062316,... ## $ score &lt;chr&gt; &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;,... ## $ strand &lt;chr&gt; &quot;+&quot;, &quot;+&quot;, &quot;+&quot;, &quot;+&quot;, &quot;-&quot;, &quot;-&quot;,... ## $ frame &lt;chr&gt; &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;, &quot;.&quot;,... ## $ gene_id &lt;chr&gt; &quot;ENSG00000233866.1&quot;, &quot;ENSG000... ## $ transcript_id &lt;chr&gt; &quot;ENSG00000233866.1&quot;, &quot;ENST000... ## $ gene_type &lt;chr&gt; &quot;lincRNA&quot;, &quot;lincRNA&quot;, &quot;lincRN... ## $ gene_name &lt;chr&gt; &quot;LA16c-4G1.3&quot;, &quot;LA16c-4G1.3&quot;,... ## $ transcript_type &lt;chr&gt; &quot;lincRNA&quot;, &quot;lincRNA&quot;, &quot;lincRN... ## $ transcript_name &lt;chr&gt; &quot;LA16c-4G1.3&quot;, &quot;LA16c-4G1.3-0... ## $ exon_number &lt;chr&gt; NA, NA, &quot;1&quot;, &quot;2&quot;, NA, NA, &quot;1&quot;... ## $ exon_id &lt;chr&gt; NA, NA, &quot;ENSE00001660730.1&quot;, ... ## $ level &lt;chr&gt; &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;, &quot;2&quot;,... ## $ remap_substituted_missing_target &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ remap_target_status &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ remap_num_mappings &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ remap_original_location &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ remap_original_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ remap_status &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ transcript_support_level &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ protein_id &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ havana_transcript &lt;chr&gt; NA, &quot;OTTHUMT00000276574.1&quot;, &quot;... ## $ havana_gene &lt;chr&gt; &quot;OTTHUMG00000140195.1&quot;, &quot;OTTH... ## $ ccdsid &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, N... ## $ ont &lt;chr&gt; NA, NA, NA, NA, NA, &quot;PGO:0000... ## $ tag &lt;chr&gt; NA, &quot;basic&quot;, &quot;basic&quot;, &quot;basic&quot;... We can see that genomic features are tagged by feature type: # summarize the number of features by tag. summarize_tag(gtf, tag = &quot;basic&quot;) ## ## FALSE TRUE ## CDS 23995 12441 ## exon 28836 16135 ## gene 184 0 ## Selenocysteine 19 6 ## start_codon 2881 1319 ## stop_codon 2235 1300 ## transcript 3901 2159 ## UTR 8512 3672 And we can use these feature type tags to filter the .gtf annotation to extract the starting and ending genomic positions for features of interest, such as features tagged “gene”: # filter gtf file to return transcript features tagged basic basic_transcripts &lt;- filter_gencode(gtf, featurearg = &quot;transcript&quot;, tagarg = &quot;basic&quot;) # or filter for features == &quot;gene&quot; genes &lt;- filter_gencode(gtf, featurearg = &quot;gene&quot;) # define the boundaries of the feature of interest # this can be slow for complicated features #gene_bounds &lt;- define_boundaries(basic_transcripts, &quot;gene_id&quot;) gene_bounds &lt;- define_boundaries(genes, &quot;gene_id&quot;) # can check the resulting tibble for sanity glimpse(gene_bounds) ## Observations: 1,263 ## Variables: 10 ## $ chr &lt;chr&gt; &quot;chr22&quot;, &quot;chr22&quot;, &quot;chr22&quot;, &quot;chr22&quot;, &quot;chr22&quot;, &quot;... ## $ strand &lt;chr&gt; &quot;+&quot;, &quot;-&quot;, &quot;-&quot;, &quot;-&quot;, &quot;+&quot;, &quot;-&quot;, &quot;-&quot;, &quot;-&quot;, &quot;+&quot;, &quot;... ## $ gene_id &lt;chr&gt; &quot;ENSG00000233866.1&quot;, &quot;ENSG00000229286.1&quot;, &quot;ENS... ## $ gene_name &lt;chr&gt; &quot;LA16c-4G1.3&quot;, &quot;LA16c-4G1.4&quot;, &quot;LA16c-4G1.5&quot;, &quot;... ## $ agg_start &lt;dbl&gt; 16062157, 16076052, 16084249, 16100517, 161227... ## $ agg_end &lt;dbl&gt; 16063236, 16076172, 16084826, 16124973, 161237... ## $ source &lt;chr&gt; &quot;HAVANA&quot;, &quot;HAVANA&quot;, &quot;HAVANA&quot;, &quot;HAVANA&quot;, &quot;HAVAN... ## $ transcript_type &lt;chr&gt; &quot;lincRNA&quot;, &quot;pseudogene&quot;, &quot;pseudogene&quot;, &quot;pseudo... ## $ merge_count &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1... ## $ agg_size &lt;dbl&gt; 1079, 120, 577, 24456, 1048, 45025, 621, 693, ... Finally, genetable includes a function to save a self-documented tab separated file containing the filtered .gtf results: # save to file note &lt;- &#39;This file includes starting and ending ranges for feature = &quot;gene&quot; in the gtf file.&#39; save_to_file(gene_bounds, notes = note) # will automatically make file called feature_bounds_DATE.tsv As insurance for this exercise, the genic range definitions that I made last week are also available on github: ben.workshop.path &lt;- &quot;https://github.com/bheavner/topmed_workshop_2017_bh/raw/master&quot; boundsfile &lt;- &quot;feature_bounds_20170804.tsv&quot; if (!file.exists(boundsfile)) download.file(file.path(ben.workshop.path, boundsfile), boundsfile) 7.5.3 Aggregating TOPMed variants into genic units Now we’ve generated a set of variants with a manaageable number of annotation fields, and defined the desired aggregation units as sets of genomic ranges. The set of variants may be filtered using the annotation fields we’ve chosen (our list is unfiltered in this example). We’re ready to aggregate the variants by genic units. As insurance, we can start with the same set of inputs by downloading what I generated last week: ben.workshop.path &lt;- &quot;https://github.com/bheavner/topmed_workshop_2017_bh/raw/master&quot; parsed_snp_file &lt;- &quot;parsed_snp.tsv&quot; parsed_indel_file &lt;- &quot;parsed_indel.tsv&quot; unit_defs_file &lt;- &quot;feature_bounds_20170804.tsv&quot; if (!file.exists(parsed_snp_file)) download.file(file.path(ben.workshop.path, parsed_snp_file), parsed_snp_file) if (!file.exists(parsed_indel_file)) download.file(file.path(ben.workshop.path, parsed_indel_file), parsed_indel_file) if (!file.exists(unit_defs_file)) download.file(file.path(ben.workshop.path, unit_defs_file), unit_defs_file) Load the tab-separated files to tibbles (data frames) to work with: snps &lt;- read_tsv(parsed_snp_file, comment = &quot;#&quot;) indels &lt;- read_tsv(parsed_indel_file, comment = &quot;#&quot;) unit_defs &lt;- read_tsv(unit_defs_file, comment = &quot;#&quot;, skip = 1) unit_defs &lt;- select(unit_defs, c(gene_id, agg_start, agg_end)) There’s probably a nice, fast, vectorized to accomplish this task, but for demonstration purposes, we’ll just loop over the unit_defs and select indels and snps within the genomic ranges of interest: # make an empty tibble foo &lt;- tibble(group_id=&quot;&quot;, chromosome=&quot;&quot;, position=&quot;&quot;, ref=&quot;&quot;, alt=&quot;&quot;) %&gt;% filter(length(group_id)&gt;1) # loop over unit defs for (rowIndex in 1:nrow(unit_defs)) { # select snps and insert to foo ## SNPs could be filtered here snpsToAdd &lt;- select(snps, c(chr, pos, ref, alt)) %&gt;% dplyr::filter(between(pos, unit_defs[rowIndex,]$agg_start, unit_defs[rowIndex,]$agg_end)) %&gt;% # This is the line to vectorize distinct() %&gt;% mutate(group_id = unit_defs[rowIndex,]$gene_id) if (nrow(snpsToAdd) &gt; 0) { foo &lt;- add_row( foo, group_id = snpsToAdd$group_id, chromosome = snpsToAdd$chr, position = snpsToAdd$pos, ref = snpsToAdd$ref, alt = snpsToAdd$alt ) } # select indels and insert to foo ## Indels could be filtered here, too toAdd &lt;- select(indels, c(chr, pos, ref, alt)) %&gt;% dplyr::filter(between(pos, unit_defs[rowIndex, ]$agg_start, unit_defs[rowIndex, ]$agg_end)) %&gt;% # to vectorize distinct() %&gt;% mutate(group_id = unit_defs[rowIndex, ]$gene_id) if (rowIndex %% 10 == 0){ message( paste0(&quot;row: &quot;, rowIndex, &quot; snps to add: &quot;, nrow(snpsToAdd), &quot; indels to add: &quot;, nrow(toAdd))) } if (nrow(toAdd) &gt; 0) { foo &lt;- add_row( foo, group_id = toAdd$group_id, chromosome = toAdd$chr, position = toAdd$pos, ref = toAdd$ref, alt = toAdd$alt ) } } aggregated_variants &lt;- distinct(foo) That may not be fast or pretty, but we’ve now got a set of variants aggregated into genic units using the GENCODE gene model! This set can be saved and used with the analysis pipeline for association testing. We can inspect the tibble with glimpse: glimpse(aggregated_variants) ## Observations: 794 ## Variables: 5 ## $ group_id &lt;chr&gt; &quot;ENSG00000231565.1&quot;, &quot;ENSG00000237299.1&quot;, &quot;ENSG0000... ## $ chromosome &lt;chr&gt; &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22&quot;, &quot;22... ## $ position &lt;chr&gt; &quot;16365024&quot;, &quot;16425814&quot;, &quot;16425814&quot;, &quot;16926604&quot;, &quot;16... ## $ ref &lt;chr&gt; &quot;A&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;G&quot;, &quot;G&quot;, &quot;C&quot;, &quot;G&quot;, &quot;A&quot;, &quot;... ## $ alt &lt;chr&gt; &quot;C&quot;, &quot;T&quot;, &quot;T&quot;, &quot;T&quot;, &quot;T&quot;, &quot;A&quot;, &quot;A&quot;, &quot;T&quot;, &quot;A&quot;, &quot;G&quot;, &quot;... We can do things like counting how many genic units we’re using: distinct(as.tibble(aggregated_variants$group_id)) ## # A tibble: 270 x 1 ## value ## &lt;chr&gt; ## 1 ENSG00000231565.1 ## 2 ENSG00000237299.1 ## 3 ENSG00000235759.1 ## 4 ENSG00000227367.1 ## 5 ENSG00000100181.17 ## 6 ENSG00000172967.7 ## 7 ENSG00000215568.3 ## 8 ENSG00000237438.2 ## 9 ENSG00000093072.11 ## 10 ENSG00000241832.1 ## # ... with 260 more rows We can look at number of variants per aggregation unit: counts &lt;- aggregated_variants %&gt;% group_by(group_id) %&gt;% summarize(n()) Feel free to look at other summary statistics and do other exploratory data analysis as you’d like, but don’t forget to save it if you’d like to use it for the analysis pipeline! save(aggregated_variants, file = &quot;chr22_gene_aggregates.RDA&quot;) 7.5.4 Aggregate unit for association testing exercise We will be using a slightly different gene-based aggregation unit for the assocation testing exercise. As before, this analysis uses a subset of the TOPMed SNP variants that are present in the 1000 Genomes Project. However, in this exercise, the genic units include TOPMed SNP variants from all chromosomes (no indels, and not just chromosome 22 as before). Further, each genic unit is expanded to include the set of TOPMed SNP variants falling within a GENCODE-defined gene along with 20 kb flanking regions upstream and downstream of that range. In a larger-scale analysis of TOPMed data, aggregation units could include both TOPMed SNP and indel variants falling within defined aggregation units, and would not be restricted to the variants also present in this chosen subset of the 1000 Genomes Project. An analyst might also choose to filter variants within each unit based on various annotations (examples include loss of function, conservation, deleteriousness scores, etc.). As before, the aggregation units are defined in an R dataframe. Each row of the dataframe specifies a variant (chromosome, position, ref, alt) and the group identifier (group_id) assigned to it. Mutiple rows with different group identifiers can be specified to assign a variant to different groups (for example a variant can be assigned to mutiple genes). aggfile &lt;- &quot;variants_by_gene.RData&quot; if (!file.exists(aggfile)) download.file(file.path(workshop.path, aggfile), aggfile) aggunit &lt;- TopmedPipeline::getobj(aggfile) names(aggunit) ## [1] &quot;group_id&quot; &quot;chromosome&quot; &quot;position&quot; &quot;ref&quot; &quot;alt&quot; head(aggunit) ## # A tibble: 6 x 5 ## group_id chromosome position ref alt ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000000005.5 X 99850725 A G ## 2 ENSG00000000938.8 1 27960254 A G ## 3 ENSG00000001084.6 6 53357691 C T ## 4 ENSG00000001084.6 6 53413986 T C ## 5 ENSG00000001084.6 6 53466979 C T ## 6 ENSG00000001167.10 6 41064020 A G # an example of variant that is present in mutiple groups library(dplyr) mult &lt;- aggunit %&gt;% group_by(chromosome, position) %&gt;% summarise(n=n()) %&gt;% filter(n &gt; 1) inner_join(aggunit, mult[2,1:2]) ## # A tibble: 4 x 5 ## group_id chromosome position ref alt ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ENSG00000188157.9 1 985900 C T ## 2 ENSG00000217801.5 1 985900 C T ## 3 ENSG00000242590.1 1 985900 C T ## 4 ENSG00000273443.1 1 985900 C T 7.5.5 Association testing with aggregate units We can run a burden test or SKAT on each of these units using the GENESIS function assocTestSeq. This function expects a list, where each element of the list is a dataframe representing a single aggregation unit and containing the unique variant.id assigned to each variant in a GDS file. We use the TopmedPipeline function aggregateListByAllele to quickly convert our single dataframe to the required format. This function can account for multiallelic variants (the same chromosome, position, and ref, but different alt alleles). The first argument is the GDS object returned by seqOpen (see above). library(TopmedPipeline) aggVarList &lt;- aggregateListByAllele(gds, aggunit) length(aggVarList) ## [1] 932 head(names(aggVarList)) ## [1] &quot;ENSG00000188157.9&quot; &quot;ENSG00000242590.1&quot; &quot;ENSG00000217801.5&quot; ## [4] &quot;ENSG00000273443.1&quot; &quot;ENSG00000131591.13&quot; &quot;ENSG00000237330.2&quot; aggVarList[[1]] ## variant.id chromosome position ref nAlleles allele allele.index ## 1 1 1 970546 C 2 G 1 ## 2 2 1 985900 C 2 T 1 As in the previous section, we must fit the null model before running the association test. assoc &lt;- assocTestSeq(seqData, nullmod, test=&quot;Burden&quot;, aggVarList=aggVarList, AF.range=c(0,0.1), weight.beta=c(1,1)) names(assoc) ## [1] &quot;param&quot; &quot;nsample&quot; &quot;results&quot; &quot;variantInfo&quot; head(assoc$results) ## n.site n.sample.alt burden.skew Score Var ## ENSG00000188157.9 2 116 2.867095 -1.3501832 0.616143773 ## ENSG00000242590.1 2 116 2.867095 -1.3501832 0.616143773 ## ENSG00000217801.5 1 107 3.041979 -1.2395028 0.550238011 ## ENSG00000273443.1 1 107 3.041979 -1.2395028 0.550238011 ## ENSG00000131591.13 1 1 33.466573 -0.2090215 0.008173804 ## ENSG00000237330.2 1 1 33.466573 -0.2090215 0.008173804 ## Score.stat Score.pval ## ENSG00000188157.9 2.958717 0.08541571 ## ENSG00000242590.1 2.958717 0.08541571 ## ENSG00000217801.5 2.792186 0.09472490 ## ENSG00000273443.1 2.792186 0.09472490 ## ENSG00000131591.13 5.345125 0.02078029 ## ENSG00000237330.2 5.345125 0.02078029 head(names(assoc$variantInfo)) ## [1] &quot;ENSG00000188157.9&quot; &quot;ENSG00000242590.1&quot; &quot;ENSG00000217801.5&quot; ## [4] &quot;ENSG00000273443.1&quot; &quot;ENSG00000131591.13&quot; &quot;ENSG00000237330.2&quot; head(assoc$variantInfo[[1]]) ## variantID allele chr pos n.obs freq weight ## 1 1 1 1 970546 1126 0.003996448 1 ## 2 2 1 1 985900 1126 0.049289520 1 qqPlot(assoc$results$Score.pval) seqClose(gds) 7.5.6 Exercise Since we are working with a subset of the data, many of the genes listed in group_id have a very small number of variants. Create a new set of units based on position rather than gene name, using the TopmedPipeline function aggregateListByPosition. Then run SKAT using those units. "],
["analysis-pipeline.html", "8 Analysis Pipeline 8.1 Running on a local cluster 8.2 Running on AWS Batch", " 8 Analysis Pipeline The DCC’s analysis pipeline is hosted on github: https://github.com/smgogarten/analysis_pipeline 8.1 Running on a local cluster To run a burden test on our local SGE cluster, first we create a config file and call it assoc_window_burden.config: out_prefix &quot;test&quot; gds_file &quot;testdata/1KG_phase3_subset_chr .gds&quot; phenotype_file &quot;testdata/1KG_phase3_subset_annot.RData&quot; pcrelate_file &quot;testdata/round2_pcrelate.gds&quot; pca_file &quot;testdata/round2_pcair.RData&quot; sample_include_file &quot;testdata/sample_include.RData&quot; variant_include_file &quot;testdata/variant_include_chr .RData&quot; outcome outcome covars &quot;sex&quot; n_pcs 4 alt_freq_range &quot;0 0.1&quot; test &quot;burden&quot; test_type &quot;score&quot; We will use the python script assoc.py to submit all jobs. First we look at the available options: setenv PIPELINE /projects/topmed/working_code/analysis_pipeline $PIPELINE/assoc.py --help Let’s run a sliding window test on chromosomes 1-10. We will also specify the cluster type, although UW_Cluster is actually the default. The last argument is our config file. First, we print the commands that will be be run without actually submitting jobs: $PIPELINE/assoc.py --chromosomes 1-10 --cluster_type UW_Cluster --print_only window testdata/assoc_window_burden.config The default segment length is 10,000 kb, but we can change that to 50,000 kb when we submit: $PIPELINE/assoc.py --chromosomes 1-10 --cluster_type UW_Cluster --segment_length 50000 window testdata/assoc_window_burden.config We can use the qstat command to check the status of our jobs. 8.2 Running on AWS Batch To run a burden test on AWS Batch, we do the following general steps: 1. Log into the the docker AMI instance 2. cd to a working directory on our EFS volume 3. Create the configuration file assoc_window_burden.config 4. Optionally execute the association pipeline specifying the AWS Batch service to print out the commands (not running the pipeline) 5. Execute the association pipeline specifying the AWS Batch service to run the pipeline 6. Monitor the pipeline via the AWS Batch console 8.2.1 Log into AWS docker image ssh into our image which is running docker. Various docker commands can be executed including running TOPMed version of R (note: TOPMed data is not part of the docker image). ssh -i ~/.ssh/&lt;some private key&gt; kuraisa@54.244.25.94 [kuraisa@ip-172-255-46-100]~ _4816$ docker images ... [kuraisa@ip-172-255-46-100]~ _4817$ docker run -it uwgac/r-topmed:dev /bin/bash /# which R ... /# R ... &gt; .libPaths() ... &gt; library(SeqArray) ... &gt; q() ... /# exit [kuraisa@ip-172-255-46-100]~ _4818$ 8.2.2 cd to working directory and create config file cd /projects/topmed/analysts/kuraisa/tm-workshop/ vi assoc_window_burden.config ... 8.2.3 Print out AWS commands if executing the pipeline python /projects/topmed/dev_code/analysis_pipeline/assoc.py \\ single ./assoc_window_burden.config \\ --cluster_type AWS_Batch --verbose \\ --cluster_file \\ /projects/topmed/dev_code/analysis_pipeline/testdata_batch.json \\ --print &gt; single_print.log 2&gt;&amp;1 8.2.4 Execute the pipeline python /projects/topmed/dev_code/analysis_pipeline/assoc.py \\ single ./assoc_window_burden.config \\ --cluster_type AWS_Batch --verbose \\ --cluster_file \\ /projects/topmed/dev_code/analysis_pipeline/testdata_batch.json \\ &gt; burden_print.log 2&gt;&amp;1 8.2.5 Monitor the jobs From the web browser, log into the AWS account and select the Batch Services to monitor: - Summary via Dashboard - Job queue Optimal_topmed_testdata - View high-level job logs You can switch to ec2 services to monitor instances being created or running to support the various jobs. "],
["analysis-commons.html", "9 Analysis Commons 9.1 Outline 9.2 Web Interface and Running an Analysis Application 9.3 Command line interface 9.4 Writing your own Apps", " 9 Analysis Commons 9.1 Outline Introduction to web-interface Running a single variant analysis Workflows and monitoring jobs Running aggregate tests (SKAT) Run batch jobs from the command line Writing your own Apps 9.2 Web Interface and Running an Analysis Application 9.2.1 Exercise 1) Run a single variant analysis. Note that the job will finish instantaneously if you don’t change the output file name. It knows that you are running the exact same job and will just reuse results from previous analyses. Log into http://dnanexus.com using the user name and password listed on the handout. Should be in the form of Username:topmed_# and Password:Topmed_#. Ignore warning about default billing account. Navigate to and select (dcc:tools/genesis_v0.7) File inputs: * phenofile -&gt; phenotype/1KG_pheno.csv * genotypefile -&gt; genotypes/1KG_phase3_subset_chr1.gds * kinship -&gt; kinship/1KG_kins.Rda * Note: orange aggregation, annotation and genefile can be left empty Parameter inputs: * output folder: output/YOURFOLDERNAME * outcome (Column name of the outcome variable): outcome * covariates (case sepecific): Population,sex * prefix for output filename: single_chr1 * test_type: Single * pheno_id: sample.id * Note: Other options can be left as their defaults, some are only used for aggreagate tests 9.2.2 Exercise 2) Run SKAT test grouping variants into gene transcript regions and limit the variants to those with a CADD phred score &gt; 2 and MAF &lt;= 5%. Italic inputs below are the same as single variant; update the parameters &amp; files to change to a SKAT test. Go to the monitor tab. Click on the Name of a job ( or someone’s ) that successfully completed the single variant analysis, then click “Launch as new Job” and modify the inputs. File inputs: * phenofile -&gt; phenotype/1KG_pheno.csv * genotypefile -&gt; genotypes/1KG_phase3_subset_chr1.gds * kinship -&gt; kinship/1KG_kins.Rda * annotation -&gt; annotation/1KG_annotation_CHR1.txt * genefile -&gt; aggregation/AggUnit_CHR1_ucscgene.csv Parameter inputs: * outcome: outcome * covariates: Population,sex * pheno_id: sample.id * output folder: output/YOURFOLDERNAME * outputfilename: skat_chr1_geneBased_CADDgt2 * test_type: SKAT * snp_filter: CADD_phred&gt;2 * min_mac:0 * top_maf: 0.05 * weights: c(1,25) 9.3 Command line interface References: * Command Line Interface Quickstart * Index of dx commands 9.3.1 Log in to AWI Replace topmed_## with the user ID from your handout $ ssh topmed_##@34.212.243.167 --timeout 2h You will be prompted for your password, e.g. Topmed_## (Note capitolization) _Please ignore login warnings $ source /usr/local/dx-toolkit/environment $ dx login Enter the following at the prompts username: topmed_## password: Topmed_## project:dcc ( type 0 to select dcc ) You can select or change project once you are logged in $ dx select dcc 9.3.2 Exercise 3) Navigate directories, make output directory, examine files File paths: &lt;project&gt;:/path/to/file.txt Example: dcc:/phenotypes/1KG_pheno.csv List directory contents: $ dx select dcc $ dx ls $ dx ls /tools $ dx ls dcc:/tools Get results from project $ dx download dcc:/phenotype/1KG_pheno.csv $ ls $ head 1KG_pheno.csv 9.3.3 Exercise 4) Run single variant analysis from command line using bash script Open the single_multichrom.sh bash script and edit to replace the output directory “YOURNAME” to your folder $ dx describe tools/genesis_v0.7 Either edit using nano $ nano single_multichrom.sh Run the App. Will loop over 2 chromosomes running the single variant analyses $ ./single_multichrom.sh 9.4 Writing your own Apps 9.4.1 Exercise 5) Write an App that creates phenotype residuals and performs an inverse normal transform Use app wizard to create template $ dx-app-wizard App Name: make_residuals Title []: Create inverse normal transformed residuals 1st input name (&lt;ENTER&gt; to finish): phenofile Label (optional human-readable name) []: CSV phenotype file Choose a class (&lt;TAB&gt; twice for choices): file This is an optional parameter [y/n]: n 2nd input name (&lt;ENTER&gt; to finish): model Label (optional human-readable name) []: model for creating residuals (e.g. outcome~age+Population ) Choose a class (&lt;TAB&gt; twice for choices): string This is an optional parameter [y/n]: n 3rd input name (&lt;ENTER&gt; to finish): prefix Label (optional human-readable name) []: Output filename prefix Choose a class (&lt;TAB&gt; twice for choices): string This is an optional parameter [y/n]: n 4th input name (&lt;ENTER&gt; to finish): &lt;ENTER&gt; 1st output name (&lt;ENTER&gt; to finish): output Label (optional human-readable name) []: Choose a class (&lt;TAB&gt; twice for choices): file Timeout policy [48h]: 1h Programming language: bash *Use defaults for other options* Look at the files created by the wizard cd make_residuals/ ls more dxapp.json Edit App executable to run an R script $ vi src/make_residuals.sh main() { echo &quot;Value of phenofile: &#39;$phenofile&#39;&quot; echo &quot;Value of model: &#39;$model&#39;&quot; echo &quot;Value of prefix: &#39;$prefix&#39;&quot; dx download &quot;$phenofile&quot; -o phenofile Rscript /make_resid.R $model output=$(dx upload output --brief) dx-jobutil-add-output output &quot;$output&quot; --class=file dx mv ${output} ${prefix}.csv } Create an R script that does the ‘work’ $ vi resources/make_resid.R args&lt;-commandArgs(TRUE) model &lt;- as.formula(args[1]) print(model) pheno = read.csv(&quot;phenofile&quot;,as.is=T) pheno$resid = residuals(lm(model,data=pheno)) pheno$invnt_resid = with(pheno,qnorm((rank(resid,na.last=&quot;keep&quot;)-0.5)/sum(!is.na(resid)))) write.csv(pheno,file=&quot;output&quot;,row.names=F) Build the App $ dx build -f make_residuals --destination=output/YOURNAME/make_residuals Run the App $ dx run output/YOURNAME/make_residuals -iphenofile=phenotype/1KG_pheno.csv \\ -imodel=outcome~sex+Population -iprefix=1kg_pheno_invnt \\ --destination=output/YOURNAME --yes Monitor Progress $ dx watch jobid 9.4.2 Optional Exercise 6) Make QQ plot Make QQ plot of your single variant results. Select results from the multiple chromosome run (chr21 and chr22). You will need to identify the p-value column name. To view the results file try these options: 1) dx download to download the results for viewing. 2) View file through web interface using Visualize ( next to Monitor near top of the page ) and select Gzipped File Previewer 3) Pipe zipped file though regular linux commands dx cat to view column names $ dx cat output/folder/file | gunzip | head Once you know the name of the p-value column, run qqplot first through web interface and then try running interactivly from the web interface then from the command line. $ dx run tools/qqplot Note: the plot label must not contain spaces. 9.4.3 Optional Exercise 7) Run conditional analysis Find the name of one associated variant in the single snp results and rerun the single variant analysis conditioning on that variant (e.g. 22:17105517). Note that the output file name cannot contain a colon (e.g. output file name cannot be single_chr22_single_22:17105517, try single_chr22_single_22_17105517 instead). 9.4.4 Optional Exercise 8) Create a regional association plot using LD extracted from your data set This process requires two steps, one to extract the LD for all variants in the region and one to create the plot. Sequencing data sets often contain variants not in external refernce panels, so it is helpful to create your own LD reference. Step 1: Run GILD (GDS Into LD) App (tools/gild_v1) File inputs: * gds_file -&gt; genotypes/1KG_phase3_subset_chr22.gds Parameter inputs: lead_snp -&gt; 22:17105517 start_pos -&gt; 1 stop_pos -&gt; 51237069 label for results file -&gt; “LD_chr22” output_LD_filename output/YOURNAME Note: this can take 10-15 mins to complete Step 2: Run AssocPlot (tools/assocplot) File inputs: datafile -&gt; single variant association results output for chr22 ldfile -&gt; Output file from Step 1 with .ld suffix Parameter inputs (Minimum required to have the App run successfully with GENESIS output): Output folder -&gt; output/YOURNAME Marker Column Name -&gt; snpID P value Column Name -&gt; Score.pval Index SNP -&gt; 22:17105517 "]
]
